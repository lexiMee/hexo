<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  <link href="//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">



<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=0.5.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Android, Audio" />





  <link rel="alternate" href="/atom.xml" title="Thinking" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=0.5.0" />






<meta name="description" content="leave me alone">
<meta property="og:type" content="website">
<meta property="og:title" content="Thinking">
<meta property="og:url" content="http://thinks.me/index.html">
<meta property="og:site_name" content="Thinking">
<meta property="og:description" content="leave me alone">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Thinking">
<meta name="twitter:description" content="leave me alone">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>

  <title> Thinking </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?1a17ff812788f97b5ec90bee6eba907f";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Thinking</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-th fa-fw"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags fa-fw"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/03/17/1_1/" itemprop="url">
                  未命名
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-03-17T11:49:42+08:00" content="2016-03-17">
              2016-03-17
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/03/17/1_1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/03/17/1_1/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-1_audiotrack的create流程">1.1 audiotrack的create流程</h1><h2 id="简述">简述</h2><p>这部分，我们主要讲解两个函数<code>getMinBufferSize</code>和<code>AudioTrack</code>。</p>
<h2 id="正文">正文</h2><h3 id="一、getMinBufferSize函数解析">一、getMinBufferSize函数解析</h3><p>直接帖整段的java的代码，不打算省略了。可能很占空间，但是我们可以把每个变量都看一遍。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getMinBufferSize</span><span class="params">(<span class="keyword">int</span> sampleRateInHz, <span class="keyword">int</span> channelConfig, <span class="keyword">int</span> audioFormat)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> channelCount = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 传入的声道配置。CHANNEL_OUT_MONO、CHANNEL_CONFIGURATION_MONO是一样的主要是为了兼容以前。</span></span><br><span class="line">    <span class="comment">// CHANNEL_OUT_MONO单声道 CHANNEL_OUT_STEREO 双声道。</span></span><br><span class="line">    <span class="keyword">switch</span>(channelConfig) &#123;</span><br><span class="line">    <span class="keyword">case</span> AudioFormat.CHANNEL_OUT_MONO:</span><br><span class="line">    <span class="keyword">case</span> AudioFormat.CHANNEL_CONFIGURATION_MONO:</span><br><span class="line">        channelCount = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> AudioFormat.CHANNEL_OUT_STEREO:</span><br><span class="line">    <span class="keyword">case</span> AudioFormat.CHANNEL_CONFIGURATION_STEREO:</span><br><span class="line">        channelCount = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="comment">// 判断是否支持全方位的声道数，总共是8个，支持的话，需要支持前左、前右、后左、后右、左边、右边</span></span><br><span class="line">        <span class="keyword">if</span> (!isMultichannelConfigSupported(channelConfig)) &#123;</span><br><span class="line">            loge(<span class="string">"getMinBufferSize(): Invalid channel configuration."</span>);</span><br><span class="line">            <span class="keyword">return</span> ERROR_BAD_VALUE;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 如果支持，就计算出它的声道数。</span></span><br><span class="line">            channelCount = AudioFormat.channelCountFromOutChannelMask(channelConfig);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 检查下format的格式是否正确。</span></span><br><span class="line">    <span class="keyword">if</span> (!AudioFormat.isPublicEncoding(audioFormat)) &#123;</span><br><span class="line">        loge(<span class="string">"getMinBufferSize(): Invalid audio format."</span>);</span><br><span class="line">        <span class="keyword">return</span> ERROR_BAD_VALUE;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// sample rate, note these values are subject to change</span></span><br><span class="line">    <span class="comment">// 确保采样率在我们规定的范围，如果自行扩展采样率的话，就需要修改这边的静态变量。</span></span><br><span class="line">    <span class="keyword">if</span> ( (sampleRateInHz &lt; SAMPLE_RATE_HZ_MIN) || (sampleRateInHz &gt; SAMPLE_RATE_HZ_MAX) ) &#123;</span><br><span class="line">        loge(<span class="string">"getMinBufferSize(): "</span> + sampleRateInHz + <span class="string">" Hz is not a supported sample rate."</span>);</span><br><span class="line">        <span class="keyword">return</span> ERROR_BAD_VALUE;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 接下来就直接调用native的方法了。</span></span><br><span class="line">    <span class="keyword">int</span> size = native_get_min_buff_size(sampleRateInHz, channelCount, audioFormat);</span><br><span class="line">    <span class="keyword">if</span> (size &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        loge(<span class="string">"getMinBufferSize(): error querying hardware"</span>);</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> size;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的函数做了几件事：</p>
<ol>
<li>将上层的channelconfig转变为声道的数量</li>
<li>判断audioformat是否是我们定义的</li>
<li>调用native的min buffer size</li>
</ol>
<p>接着来看native的代码。</p>
<pre><code><span class="function"><span class="keyword">static</span> jint <span class="title">android_media_AudioTrack_get_min_buff_size</span><span class="params">(JNIEnv *env,  jobject thiz,
    jint sampleRateInHertz, jint channelCount, jint audioFormat)</span> </span>{

    <span class="keyword">size_t</span> frameCount;
    <span class="comment">// 通过AudioTrack去获取需要的最少的帧数。</span>
    <span class="keyword">const</span> <span class="keyword">status_t</span> status = AudioTrack::getMinFrameCount(&amp;frameCount, AUDIO_STREAM_DEFAULT,
            sampleRateInHertz);
    <span class="keyword">if</span> (status != NO_ERROR) {
        <span class="keyword">return</span> -<span class="number">1</span>;
    }
    <span class="comment">// 将上层的audioFormat转换成native的格式 java层是一个递增索引，在native是位活的形式</span>
    <span class="keyword">const</span> <span class="keyword">audio_format_t</span> format = audioFormatToNative(audioFormat);
    <span class="comment">// 判断是否是线性的pcm数据流，因为只有线性数据流我们才能计算出帧对应多少字节。</span>
    <span class="keyword">if</span> (audio_is_linear_pcm(format)) {
        <span class="comment">// 获取每一帧占多少个字节</span>
        <span class="keyword">const</span> <span class="keyword">size_t</span> bytesPerSample = audio_bytes_per_sample(format);
        <span class="comment">// 帧数 * 每帧字节数 * 通道数 就是我们所要得到的buffer的字节数了。</span>
        <span class="keyword">return</span> frameCount * channelCount * bytesPerSample;
    } <span class="keyword">else</span> {
        <span class="keyword">return</span> frameCount;
    }
}
</code></pre><p>上面的代码牵扯到一个帧到字节的计算方式。<br><em>buffersize = 帧数 x 每帧占用字节数 x 通道数</em></p>
<p>每帧占用字节数如下图：<br><img src="http://thinks.me/image/audioformat.jpg" alt=""></p>
<p>现在还有多少帧是未知的了，我们来看下函数<code>AudioTrack::getMinFrameCount</code></p>
<pre><code><span class="keyword">status_t</span> AudioTrack::getMinFrameCount(
        <span class="keyword">size_t</span>* frameCount,
        <span class="keyword">audio_stream_type_t</span> streamType,
        <span class="keyword">uint32_t</span> sampleRate)
{
    <span class="keyword">if</span> (frameCount == <span class="literal">NULL</span>) {
        <span class="keyword">return</span> BAD_VALUE;
    }

    <span class="comment">// FIXME handle in server, like createTrack_l(), possible missing info:</span>
    <span class="comment">//          audio_io_handle_t output</span>
    <span class="comment">//          audio_format_t format</span>
    <span class="comment">//          audio_channel_mask_t channelMask</span>
    <span class="comment">//          audio_output_flags_t flags (FAST)</span>
    <span class="keyword">uint32_t</span> afSampleRate;
    <span class="keyword">status_t</span> status;
    <span class="comment">// 获取streamtype下，对应output的采样率</span>
    status = AudioSystem::getOutputSamplingRate(&amp;afSampleRate, streamType);
    <span class="keyword">if</span> (status != NO_ERROR) {
        <span class="keyword">return</span> status;
    }
    <span class="keyword">size_t</span> afFrameCount;
    <span class="comment">// 获取streamtype下，对应output的hal层的buffer size对应的帧数，采样率为当时output默认。</span>
    status = AudioSystem::getOutputFrameCount(&amp;afFrameCount, streamType);
    <span class="keyword">if</span> (status != NO_ERROR) {
        <span class="keyword">return</span> status;
    }
    <span class="keyword">uint32_t</span> afLatency;
    <span class="comment">// 获取streamtype下，对应output的hal层latency的大小,单位是ms</span>
    status = AudioSystem::getOutputLatency(&amp;afLatency, streamType);
    <span class="keyword">if</span> (status != NO_ERROR) {
        <span class="keyword">return</span> status;
    }

    <span class="comment">// When called from createTrack, speed is 1.0f (normal speed).</span>
    <span class="comment">// This is rechecked again on setting playback rate (<span class="doctag">TODO:</span> on setting sample rate, too).</span>
    <span class="comment">// 开始计算所需要的最少帧数</span>
    *frameCount = calculateMinFrameCount(afLatency, afFrameCount, afSampleRate, sampleRate, <span class="number">1.0f</span>);

    <span class="keyword">if</span> (*frameCount == <span class="number">0</span>) {
        <span class="keyword">return</span> BAD_VALUE;
    }
    <span class="keyword">return</span> NO_ERROR;
}
</code></pre><p>该函数的逻辑，主要是去获取output的一些信息，采样率、latency、底层buffer对应的帧数，然后计算所需要的最少帧数。</p>
<pre><code><span class="function"><span class="keyword">static</span> size_t <span class="title">calculateMinFrameCount</span><span class="params">(
        uint32_t afLatencyMs, uint32_t afFrameCount, uint32_t afSampleRate,
        uint32_t sampleRate, <span class="keyword">float</span> speed)</span>
</span>{
    <span class="comment">// Ensure that buffer depth covers at least audio hardware latency</span>
    <span class="comment">// 确保buffer大小最少能够覆盖硬件的延时</span>
    <span class="comment">// 算法就是latency 除以 底层buffer大小在当前采样率下播放完所需花费的时间，这个就是多少倍了。</span>
    <span class="keyword">uint32_t</span> minBufCount = afLatencyMs / ((<span class="number">1000</span> * afFrameCount) / afSampleRate);
    <span class="comment">// 这个倍数不能小于2，最少必须等于2.就是说，如果latencyms比buffer还短，那就只需要两倍buffer的ms</span>
    <span class="keyword">if</span> (minBufCount &lt; <span class="number">2</span>) {
        minBufCount = <span class="number">2</span>;
    }
    <span class="comment">// sourceFramesNeededWithTimestretch这个函数里面包括了SRC的计算，和spee的的部分我们就不贴了。</span>
    <span class="keyword">return</span> <span class="function">minBufCount * <span class="title">sourceFramesNeededWithTimestretch</span><span class="params">(
            sampleRate, afFrameCount, afSampleRate, speed)</span></span>;
}
</code></pre><p>上面的计算过程就不再细看了，算法：<br><em>size_t((uint64_t)dstFramesRequired x srcSampleRate / dstSampleRate + 1 + 1) </em></p>
<p>我们继续看函数<code>AudioSystem::getOutputSamplingRate</code>.</p>
<pre><code><span class="keyword">status_t</span> AudioSystem::getOutputSamplingRate(<span class="keyword">uint32_t</span>* samplingRate, <span class="keyword">audio_stream_type_t</span> streamType)
{
    <span class="keyword">audio_io_handle_t</span> output;
    <span class="comment">// 如果stream type为默认的话，则改成为music，其实java层获取minsize的时候，并没有传递该参数</span>
    <span class="comment">// 所以获取的是music类型的。</span>
    <span class="keyword">if</span> (streamType == AUDIO_STREAM_DEFAULT) {
        streamType = AUDIO_STREAM_MUSIC;
    }
    <span class="comment">// 通过该stream type去寻找对应的output</span>
    output = getOutput(streamType);
    <span class="keyword">if</span> (output == <span class="number">0</span>) {
        <span class="keyword">return</span> PERMISSION_DENIED;
    }
    <span class="comment">// 通过output去获取samplingRate</span>
    <span class="keyword">return</span> getSamplingRate(output, samplingRate);
}
</code></pre><p>该函数的逻辑：</p>
<ol>
<li>获取output，这个output对应到AudioFlinger中的某个output thread，每个thread都会含有一个hal的output。</li>
<li>通过这个output去获取hal层当前设置的samplingRate。</li>
</ol>
<p>我们一起来看下<code>getOutput</code>函数，由于这个函数会一路调用到AudioPolicyManager中，所以我这边直接就贴AudioPolicy部分的代码。</p>
<p>这部分牵扯到了AudioPolicy部分。每一个output都对应到audio_policy.conf中的一个port节点。</p>
<pre><code>audio_io_handle_t AudioPolicyManager::getOutput(audio_stream_type_t stream,
                                                uint32_t samplingRate,
                                                audio_format_t format,
                                                audio_channel_mask_t channelMask,
                                                audio_output_flags_t flags,
                                                <span class="keyword">const</span> audio_offload_info_t *offloadInfo)
{
    <span class="comment">// 通过stream type去获取路由策略</span>
    routing_strategy strategy = getStrategy(stream);
    <span class="comment">// 通过策略去选择输出的device</span>
    audio_devices_t device = getDeviceForStrategy(strategy, <span class="keyword">false</span> <span class="comment">/*fromCache*/</span>);
    <span class="comment">// 通过device来选择输出的output</span>
    <span class="keyword">return</span> getOutputForDevice(device, AUDIO_SESSION_ALLOCATE,
                              stream, samplingRate,format, channelMask,
                              flags, offloadInfo);
}

audio_io_handle_t AudioPolicyManager::getOutputForDevice(
        audio_devices_t device,
        audio_session_t session __unused,
        audio_stream_type_t stream,
        uint32_t samplingRate,
        audio_format_t format,
        audio_channel_mask_t channelMask,
        audio_output_flags_t flags,
        <span class="keyword">const</span> audio_offload_info_t *offloadInfo)
{
    audio_io_handle_t output = AUDIO_IO_HANDLE_NONE;
    uint32_t latency = <span class="number">0</span>;
    status_t status;

    <span class="comment">// open a direct output if required by specified parameters</span>
    <span class="comment">//force direct flag if offload flag is set: offloading implies a direct output stream</span>
    <span class="comment">// and all common behaviors are driven by checking only the direct flag</span>
    <span class="comment">// this should normally be set appropriately in the policy configuration file</span>
    <span class="comment">// 如果flag中指定AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD、AUDIO_OUTPUT_FLAG_HW_AV_SYNC则会</span>
    <span class="comment">// 强制成AUDIO_OUTPUT_FLAG_DIRECT,因为offloading就意味着direct output，后面只需要判断该flag</span>
    <span class="comment">// 就可以了。</span>
    <span class="keyword">if</span> ((flags &amp; AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) != <span class="number">0</span>) {
        flags = (audio_output_flags_t)(flags | AUDIO_OUTPUT_FLAG_DIRECT);
    }
    <span class="keyword">if</span> ((flags &amp; AUDIO_OUTPUT_FLAG_HW_AV_SYNC) != <span class="number">0</span>) {
        flags = (audio_output_flags_t)(flags | AUDIO_OUTPUT_FLAG_DIRECT);
    }
    <span class="comment">// 只允许stream type为music的可以使用deep buffer</span>
    <span class="keyword">if</span> (stream != AUDIO_STREAM_MUSIC) {
        flags = (audio_output_flags_t)(flags &amp;~AUDIO_OUTPUT_FLAG_DEEP_BUFFER);
    } <span class="keyword">else</span> <span class="keyword">if</span> (<span class="comment">/* stream == AUDIO_STREAM_MUSIC &amp;&amp; */</span>
            flags == AUDIO_OUTPUT_FLAG_NONE &amp;&amp;
            property_get_bool(<span class="string">"audio.deep_buffer.media"</span>, <span class="keyword">false</span> <span class="comment">/* default_value */</span>)) {
        <span class="comment">// use DEEP_BUFFER as default output for music stream type</span>
        flags = (audio_output_flags_t)AUDIO_OUTPUT_FLAG_DEEP_BUFFER;
    }
    <span class="keyword">if</span> (stream == AUDIO_STREAM_TTS) {
        flags = AUDIO_OUTPUT_FLAG_TTS;
    }

    sp&lt;IOProfile&gt; profile;

    <span class="comment">// 如果明显是使用mixed output或者没有明确要求的使用direct output，则直接调到non_direct_output</span>
    <span class="keyword">if</span> (((flags &amp; AUDIO_OUTPUT_FLAG_DIRECT) == <span class="number">0</span>) &amp;&amp;
            audio_is_linear_pcm(format) &amp;&amp; samplingRate &lt;= MAX_MIXER_SAMPLING_RATE &amp;&amp;
            audio_channel_count_from_out_mask(channelMask) &lt;= <span class="number">2</span>) {
        <span class="keyword">goto</span> non_direct_output;
    }

    <span class="comment">// Do not allow offloading if one non offloadable effect is enabled. This prevents from</span>
    <span class="comment">// creating an offloaded track and tearing it down immediately after start when audioflinger</span>
    <span class="comment">// detects there is an active non offloadable effect.</span>
    <span class="comment">// <span class="doctag">FIXME:</span> We should check the audio session here but we do not have it in this context.</span>
    <span class="comment">// This may prevent offloading in rare situations where effects are left active by apps</span>
    <span class="comment">// in the background.</span>
    <span class="comment">// 必须保证mEffects中的效果，所有的使能的效果并且属于media必须support offload effect，或者没有</span>
    <span class="comment">// 效果才可以offloading。</span>
    <span class="comment">// isNonOffloadableEffectEnabled该函数的实现是，只有effect使能并且属于media策略</span>
    <span class="comment">// 并且不support offload effect的时候才返回true。默认基本上都是返回false的。</span>
    <span class="keyword">if</span> (((flags &amp; AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) == <span class="number">0</span>) ||
            !mEffects.isNonOffloadableEffectEnabled()) {
        profile = getProfileForDirectOutput(device,
                                           samplingRate,
                                           format,
                                           channelMask,
                                           (audio_output_flags_t)flags);
    }

    <span class="keyword">if</span> (profile != <span class="number">0</span>) {
        sp&lt;SwAudioOutputDescriptor&gt; outputDesc = <span class="keyword">NULL</span>;

        <span class="keyword">for</span> (size_t i = <span class="number">0</span>; i &lt; mOutputs.size(); i++) {
            sp&lt;SwAudioOutputDescriptor&gt; desc = mOutputs.valueAt(i);
            <span class="keyword">if</span> (!desc-&gt;isDuplicated() &amp;&amp; (profile == desc-&gt;mProfile)) {
                outputDesc = desc;
                <span class="comment">// 如果找到互相匹配的direct output则直接复用，引用计数+1</span>
                <span class="keyword">if</span> ((samplingRate == outputDesc-&gt;mSamplingRate) &amp;&amp;
                        (format == outputDesc-&gt;mFormat) &amp;&amp;
                        (channelMask == outputDesc-&gt;mChannelMask)) {
                    outputDesc-&gt;mDirectOpenCount++;
                    <span class="keyword">return</span> mOutputs.keyAt(i);
                }
            }
        }
        <span class="comment">// 如果有找到对应的direct output，但是参数不一样，则先关闭处理，如果当前该output</span>
        <span class="comment">// 有音频流在输出的话，会怎么样呢？？</span>
        <span class="keyword">if</span> (outputDesc != <span class="keyword">NULL</span>) {
            closeOutput(outputDesc-&gt;mIoHandle);
        }

        <span class="comment">// 如果选中的profile是一个offloaded，但是没有指定特殊参数，则使用默认值</span>
        audio_offload_info_t defaultOffloadInfo = AUDIO_INFO_INITIALIZER;
        <span class="keyword">if</span> ((profile-&gt;mFlags &amp; AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) &amp;&amp; !offloadInfo) {
            flags = (audio_output_flags_t)(flags | AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD);
            defaultOffloadInfo.sample_rate = samplingRate;
            defaultOffloadInfo.channel_mask = channelMask;
            defaultOffloadInfo.format = format;
            defaultOffloadInfo.stream_type = stream;
            defaultOffloadInfo.bit_rate = <span class="number">0</span>;
            defaultOffloadInfo.duration_us = -<span class="number">1</span>;
            defaultOffloadInfo.has_video = <span class="keyword">true</span>; <span class="comment">// conservative</span>
            defaultOffloadInfo.is_streaming = <span class="keyword">true</span>; <span class="comment">// likely</span>
            offloadInfo = &amp;defaultOffloadInfo;
        }
        <span class="comment">// 重新构造对象</span>
        outputDesc = <span class="keyword">new</span> SwAudioOutputDescriptor(profile, mpClientInterface);
        <span class="comment">// 设置这个output当前选择的输出设备</span>
        outputDesc-&gt;mDevice = device;
        <span class="comment">// output latency设置为0</span>
        outputDesc-&gt;mLatency = <span class="number">0</span>;
        outputDesc-&gt;mFlags = (audio_output_flags_t)(outputDesc-&gt;mFlags | flags);
        audio_config_t config = AUDIO_CONFIG_INITIALIZER;
        config.sample_rate = samplingRate;
        config.channel_mask = channelMask;
        config.format = format;
        <span class="keyword">if</span> (offloadInfo != <span class="keyword">NULL</span>) {
            config.offload_info = *offloadInfo;
        }
        <span class="comment">// 这是要通知到AudioFlinger那边去打开output，并且让output thread跑起来</span>
        status = mpClientInterface-&gt;openOutput(profile-&gt;getModuleHandle(),
                                               &amp;output,
                                               &amp;config,
                                               &amp;outputDesc-&gt;mDevice,
                                               String8(<span class="string">""</span>),
                                               &amp;outputDesc-&gt;mLatency,
                                               outputDesc-&gt;mFlags);

        <span class="comment">// 只能接受符合要求参数的output</span>
        <span class="keyword">if</span> (status != NO_ERROR ||
            (samplingRate != <span class="number">0</span> &amp;&amp; samplingRate != config.sample_rate) ||
            (format != AUDIO_FORMAT_DEFAULT &amp;&amp; format != config.format) ||
            (channelMask != <span class="number">0</span> &amp;&amp; channelMask != config.channel_mask)) {
            <span class="keyword">if</span> (output != AUDIO_IO_HANDLE_NONE) {
                mpClientInterface-&gt;closeOutput(output);
            }
            <span class="comment">// 如果direct output没有被打开，并且符合下面条件，则回到mixer output去。</span>
            <span class="keyword">if</span> (audio_is_linear_pcm(format) &amp;&amp; samplingRate &lt;= MAX_MIXER_SAMPLING_RATE) {
                <span class="keyword">goto</span> non_direct_output;
            }
            <span class="keyword">return</span> AUDIO_IO_HANDLE_NONE;
        }
        outputDesc-&gt;mSamplingRate = config.sample_rate;
        outputDesc-&gt;mChannelMask = config.channel_mask;
        outputDesc-&gt;mFormat = config.format;
        outputDesc-&gt;mRefCount[stream] = <span class="number">0</span>;
        outputDesc-&gt;mStopTime[stream] = <span class="number">0</span>;
        outputDesc-&gt;mDirectOpenCount = <span class="number">1</span>;
        <span class="comment">// 未将该output添加进来之前，先获取一次output，对于打开的output中，优先offload、</span>
        <span class="comment">// deep buffer，（通过flag判断）最后选择打开列表中的第一个。</span>
        audio_io_handle_t srcOutput = getOutputForEffect();
        <span class="comment">// 将这个output添加到AudioPolicy的mOutputs中来。</span>
        addOutput(output, outputDesc);
        audio_io_handle_t dstOutput = getOutputForEffect();
        <span class="comment">// output发生迁移，全局效果跟着迁移。</span>
        <span class="keyword">if</span> (dstOutput == output) {
            mpClientInterface-&gt;moveEffects(AUDIO_SESSION_OUTPUT_MIX, srcOutput, dstOutput);
        }
        mPreviousOutputs = mOutputs;
        mpClientInterface-&gt;onAudioPortListUpdate();
        <span class="keyword">return</span> output;
    }

non_direct_output:
    <span class="comment">// 这边不用去管channel mask，因为mixer具有downmix的能力</span>
    <span class="comment">// 打开一个非direct output</span>
    <span class="comment">// 对于非direct output，只支持pcm</span>
    <span class="keyword">if</span> (audio_is_linear_pcm(format)) {
        <span class="comment">// get which output is suitable for the specified stream. The actual</span>
        <span class="comment">// routing change will happen when startOutput() will be called</span>
        <span class="comment">// 根据指定的stream type获取哪一些output是合适的。发生routing是在startOutput函数。</span>
        SortedVector&lt;audio_io_handle_t&gt; outputs = getOutputsForDevice(device, mOutputs);

        <span class="comment">// 到这个阶段，我们可以去掉DIRECT flag，因为没有direct output会被发现了。</span>
        flags = (audio_output_flags_t)(flags &amp; ~AUDIO_OUTPUT_FLAG_DIRECT);
        <span class="comment">// 获取output，优先级：flag一致越多的 &gt; primary output &gt; 数组中第一个output</span>
        output = selectOutput(outputs, flags, format);
    }
    <span class="keyword">return</span> output;
}
</code></pre><p>函数的主要逻辑是：</p>
<ol>
<li>通过stream type获取路由策略</li>
<li>通过路由策略获取输出设备</li>
<li>通过输出设备获取输出的output 到这边就跟AudioFlinger中的output thread挂钩了。</li>
</ol>
<p><code>getOutputForDevice</code>这个函数的主要逻辑是：</p>
<ol>
<li>根据传入的flag进行判断选择什么样的output。</li>
<li>如果是direct的output，则需要参数完全一致，否则关闭，重新配置打开这个direct output，打开失败回到non direct output来。</li>
<li>如果是non direct output的话，会按照一定优先级来选择</li>
</ol>
<p>这边留下一个疑问，如果一个offload的output当前正在playback，那上面的close会触发什么，或者带来什么改变？</p>
<p>我们一开始只是关注获取output，结果却看了如此多的代码。。。output值其实是AudioFlinger那边一个thread的索引，通过这个值，我们就可以从AudioFlinger中拿到这个对象。</p>
<p>我们回到函数<code>AudioSystem::getOutputSamplingRate</code>，接着看里面的<code>getSamplingRate</code>部分。</p>
<pre><code><span class="keyword">status_t</span> AudioSystem::getSamplingRate(<span class="keyword">audio_io_handle_t</span> output,
                                      <span class="keyword">uint32_t</span>* samplingRate)
{
    <span class="comment">// 获取到AudioFlinger的binder。</span>
    <span class="keyword">const</span> sp&lt;IAudioFlinger&gt;&amp; af = AudioSystem::get_audio_flinger();
    <span class="keyword">if</span> (af == <span class="number">0</span>) <span class="keyword">return</span> PERMISSION_DENIED;
    <span class="comment">// 看本地是否有存储该output对应的对象，如果有则直接获取，如果没有则通过AudioFlinger去获取</span>
    sp&lt;AudioIoDescriptor&gt; outputDesc = getIoDescriptor(output);
    <span class="keyword">if</span> (outputDesc == <span class="number">0</span>) {
        *samplingRate = af-&gt;sampleRate(output);
    } <span class="keyword">else</span> {
        *samplingRate = outputDesc-&gt;mSamplingRate;
    }
    <span class="keyword">if</span> (*samplingRate == <span class="number">0</span>) {
        <span class="keyword">return</span> BAD_VALUE;
    }
    <span class="keyword">return</span> NO_ERROR;
}
<span class="comment">// 我们来看下这个获取flinger的函数，因为它会注册当前的信息到AudioFlinger，所以显得较为重要。</span>
<span class="keyword">const</span> sp&lt;IAudioFlinger&gt; AudioSystem::get_audio_flinger()
{
    sp&lt;IAudioFlinger&gt; af;
    sp&lt;AudioFlingerClient&gt; afc;
    {
        Mutex::Autolock _l(gLock);
        <span class="comment">// 全局变量gAudioFlinger如果为0，说明这个进程第一次访问AudioFlinger，才需要去获取跟注册。</span>
        <span class="keyword">if</span> (gAudioFlinger == <span class="number">0</span>) {
            <span class="comment">// 获取service的逻辑</span>
            sp&lt;IServiceManager&gt; sm = defaultServiceManager();
            sp&lt;IBinder&gt; binder;
            <span class="keyword">do</span> {
                binder = sm-&gt;getService(String16(<span class="string">"media.audio_flinger"</span>));
                <span class="keyword">if</span> (binder != <span class="number">0</span>)
                    <span class="keyword">break</span>;
                ALOGW(<span class="string">"AudioFlinger not published, waiting..."</span>);
                usleep(<span class="number">500000</span>); <span class="comment">// 0.5 s</span>
            } <span class="keyword">while</span> (<span class="literal">true</span>);
            <span class="comment">// 如果全局gAudioFlingerClient为null 说明尚未注册到AudioFlinger中，则创建一个。</span>
            <span class="keyword">if</span> (gAudioFlingerClient == <span class="literal">NULL</span>) {
                gAudioFlingerClient = <span class="keyword">new</span> AudioFlingerClient();
            } <span class="keyword">else</span> {
                <span class="comment">// 否则看下是否有这个回调函数，有的话则回调。</span>
                <span class="keyword">if</span> (gAudioErrorCallback) {
                    gAudioErrorCallback(NO_ERROR);
                }
            }
            <span class="comment">// AudioFlinger挂掉的话会通知gAudioFlingerClient去调用自己的binderDied方法</span>
            binder-&gt;linkToDeath(gAudioFlingerClient);
            <span class="comment">// 将该binder对象存储起来</span>
            gAudioFlinger = interface_cast&lt;IAudioFlinger&gt;(binder);
            <span class="comment">// 将client对象存储起来</span>
            afc = gAudioFlingerClient;
        }
        af = gAudioFlinger;
    }
    <span class="comment">// 如果afc不为空，则注册到AudioFlinger中去。AudioFlinger中会根据pid进行绑定。</span>
    <span class="comment">// AudioFlinger那边会给thread发送open output的信息，这样thread会拼装一个iodesc回来给到</span>
    <span class="comment">// AudioSystem，由这边来进行维护output的信息。</span>
    <span class="keyword">if</span> (afc != <span class="number">0</span>) {
        af-&gt;registerClient(afc);
    }
    <span class="keyword">return</span> af;
}
</code></pre><p>到这边我们就知道怎么获取到的samplingRate了，它的值是存储在output thread中的，你可能还是想知道这个samplingRate是从哪里来的，前面我们其实也看到了open output的一些代码了，那边我们是有传递samplingRate进去的，也就是说，这个samplingRate的值基本上就是第一个打开这个output的时候设置的，除非后面有通过setparameter进行重新设置，否则这个值就是这样了。它也必须跟audio_policy.conf中一致的。</p>
<p>到这边我们就回过头来看函数<code>AudioTrack::getMinFrameCount</code></p>
<p>我们已经有output了，并且获取到了samplingRate了，那接下来就是framecount和latency，而这两个值都是hal层的数据。并不是我们open output的时候传递进去的，不过获取的逻辑基本上跟上面获取samplingRate是一致的。</p>
<p>这样我们就获取到所有我们想要的数据了。就可以计算出MinBufferSize</p>
<p>由于我们是通过<code>getMinBufferSize</code>一路调下来的，它传递给底层的参数实在太有限了，所以基本上这个获取到的是primary的相关信息。我们可以看到在AudioTrack中调用<code>getMinFrameCount</code>也就只有采样率会保存下来，但是并不会用来跟AudioPolicy和AudioFlinger打交道。所以获取到的buffersize是跟实际有点差别的。但是你又不得不遵循就是了。</p>
<h3 id="二、AudioTrack的创建流程">二、AudioTrack的创建流程</h3><p>我们从java这边的构造函数开始。</p>
<pre><code><span class="function"><span class="keyword">public</span> <span class="title">AudioTrack</span><span class="params">(AudioAttributes attributes, AudioFormat format, <span class="keyword">int</span> bufferSizeInBytes,
        <span class="keyword">int</span> mode, <span class="keyword">int</span> sessionId)</span>
                throws IllegalArgumentException </span>{
    <span class="comment">// mState already == STATE_UNINITIALIZED</span>
    <span class="comment">// 例行检查</span>
    <span class="keyword">if</span> (attributes == null) {
        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal null AudioAttributes"</span>);
    }
    <span class="keyword">if</span> (format == null) {
        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal null AudioFormat"</span>);
    }

    <span class="comment">// 记录下和audiotrack实例关联的looper。</span>
    Looper looper;
    <span class="keyword">if</span> ((looper = Looper.myLooper()) == null) {
        looper = Looper.getMainLooper();
    }

    <span class="keyword">int</span> rate = <span class="number">0</span>;
    <span class="comment">// 看下format参数中是否带有采样率，如果有，则直接从format对象中获取，否则从获取primary output的</span>
    <span class="keyword">if</span> ((format.getPropertySetMask() &amp; AudioFormat.AUDIO_FORMAT_HAS_PROPERTY_SAMPLE_RATE) != <span class="number">0</span>)
    {
        rate = format.getSampleRate();
    } <span class="keyword">else</span> {
        rate = AudioSystem.getPrimaryOutputSamplingRate();
        <span class="keyword">if</span> (rate &lt;= <span class="number">0</span>) {
            rate = <span class="number">44100</span>;
        }
    }
    <span class="keyword">int</span> channelIndexMask = <span class="number">0</span>;
    <span class="comment">// 同上，看下是否包含channel的信息。</span>
    <span class="keyword">if</span> ((format.getPropertySetMask()
            &amp; AudioFormat.AUDIO_FORMAT_HAS_PROPERTY_CHANNEL_INDEX_MASK) != <span class="number">0</span>) {
        channelIndexMask = format.getChannelIndexMask();
    }
    <span class="keyword">int</span> channelMask = <span class="number">0</span>;
    <span class="keyword">if</span> ((format.getPropertySetMask()
            &amp; AudioFormat.AUDIO_FORMAT_HAS_PROPERTY_CHANNEL_MASK) != <span class="number">0</span>) {
        channelMask = format.getChannelMask();
    } <span class="keyword">else</span> <span class="keyword">if</span> (channelIndexMask == <span class="number">0</span>) { <span class="comment">// if no masks at all, use stereo</span>
        channelMask = AudioFormat.CHANNEL_OUT_FRONT_LEFT
                | AudioFormat.CHANNEL_OUT_FRONT_RIGHT;
    }
    <span class="keyword">int</span> encoding = AudioFormat.ENCODING_DEFAULT;
    <span class="keyword">if</span> ((format.getPropertySetMask() &amp; AudioFormat.AUDIO_FORMAT_HAS_PROPERTY_ENCODING) != <span class="number">0</span>) {
        encoding = format.getEncoding();
    }
    <span class="comment">// 检测参数是否正确</span>
    audioParamCheck(rate, channelMask, channelIndexMask, encoding, mode);
    <span class="comment">// 采用AudioAttributes的形式，则该变量会被设置为default</span>
    mStreamType = AudioSystem.STREAM_DEFAULT;
    <span class="comment">// 很粗略的判断了下我们申请的buffersize是否合法。</span>
    audioBuffSizeCheck(bufferSizeInBytes);

    mInitializationLooper = looper;
    IBinder b = ServiceManager.getService(Context.APP_OPS_SERVICE);
    mAppOps = IAppOpsService.Stub.asInterface(b);

    mAttributes = <span class="keyword">new</span> AudioAttributes.Builder(attributes).build();
    <span class="comment">// sessionId和音效挂钩部分</span>
    <span class="keyword">if</span> (sessionId &lt; <span class="number">0</span>) {
        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Invalid audio session ID: "</span>+sessionId);
    }

    <span class="keyword">int</span>[] session = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">1</span>];
    session[<span class="number">0</span>] = sessionId;
    <span class="comment">// 调用native的函数进行初始化 数据加载模式被传到jni了</span>
    <span class="keyword">int</span> initResult = native_setup(<span class="keyword">new</span> WeakReference&lt;AudioTrack&gt;(<span class="keyword">this</span>), mAttributes,
            mSampleRate, mChannelMask, mChannelIndexMask, mAudioFormat,
            mNativeBufferSizeInBytes, mDataLoadMode, session);
    <span class="keyword">if</span> (initResult != SUCCESS) {
        <span class="keyword">return</span>; <span class="comment">// with mState == STATE_UNINITIALIZED</span>
    }

    mSessionId = session[<span class="number">0</span>];
    <span class="comment">// 数据加载模式 针对已经native出来之后状态的设置。非static的，设置成STATE_INITIALIZED</span>
    <span class="keyword">if</span> (mDataLoadMode == MODE_STATIC) {
        mState = STATE_NO_STATIC_DATA;
    } <span class="keyword">else</span> {
        mState = STATE_INITIALIZED;
    }
}
</code></pre><p>上面基本上大部分都在核对参数是否合理，然后调用native的函数进行初始化。</p>
<p>接下来我们来看下native的初始化函数：</p>
<pre><code><span class="function"><span class="keyword">static</span> jint
<span class="title">android_media_AudioTrack_setup</span><span class="params">(JNIEnv *env, jobject thiz, jobject weak_this,
        jobject jaa,
        jint sampleRateInHertz, jint channelPositionMask, jint channelIndexMask,
        jint audioFormat, jint buffSizeInBytes, jint memoryMode, jintArray jSession)</span> </span>{
    <span class="comment">// jaa是AudioAttributes对象，这个对象不允许为空</span>
    <span class="keyword">if</span> (jaa == <span class="number">0</span>) {
        <span class="keyword">return</span> (jint) AUDIO_JAVA_ERROR;
    }

    <span class="comment">// Invalid channel representations are caught by !audio_is_output_channel() below.</span>
    <span class="comment">// 将java的channelmask映射成native的ChannelMask。</span>
    <span class="keyword">audio_channel_mask_t</span> nativeChannelMask = nativeChannelMaskFromJavaChannelMasks(
            channelPositionMask, channelIndexMask);
    <span class="keyword">if</span> (!audio_is_output_channel(nativeChannelMask)) {
        <span class="keyword">return</span> (jint) AUDIOTRACK_ERROR_SETUP_INVALIDCHANNELMASK;
    }
    <span class="comment">// 换算出channelCount</span>
    <span class="keyword">uint32_t</span> channelCount = audio_channel_count_from_out_mask(nativeChannelMask);

    <span class="comment">// 检查format</span>
    <span class="keyword">audio_format_t</span> format = audioFormatToNative(audioFormat);
    <span class="keyword">if</span> (format == AUDIO_FORMAT_INVALID) {
        <span class="keyword">return</span> (jint) AUDIOTRACK_ERROR_SETUP_INVALIDFORMAT;
    }

    <span class="comment">// 计算frame count</span>
    <span class="keyword">size_t</span> frameCount;
    <span class="keyword">if</span> (audio_is_linear_pcm(format)) {
        <span class="keyword">const</span> <span class="keyword">size_t</span> bytesPerSample = audio_bytes_per_sample(format);
        frameCount = buffSizeInBytes / (channelCount * bytesPerSample);
    } <span class="keyword">else</span> {
        frameCount = buffSizeInBytes;
    }

    jclass clazz = env-&gt;GetObjectClass(thiz);
    <span class="keyword">if</span> (clazz == <span class="literal">NULL</span>) {
        <span class="keyword">return</span> (jint) AUDIOTRACK_ERROR_SETUP_NATIVEINITFAILED;
    }
    <span class="comment">// session数组不能为空</span>
    <span class="keyword">if</span> (jSession == <span class="literal">NULL</span>) {
        <span class="keyword">return</span> (jint) AUDIO_JAVA_ERROR;
    }
    <span class="comment">// session中不能一个对象都没有。</span>
    jint* nSession = (jint *) env-&gt;GetPrimitiveArrayCritical(jSession, <span class="literal">NULL</span>);
    <span class="keyword">if</span> (nSession == <span class="literal">NULL</span>) {
        <span class="keyword">return</span> (jint) AUDIO_JAVA_ERROR;
    }
    <span class="keyword">int</span> sessionId = nSession[<span class="number">0</span>];
    env-&gt;ReleasePrimitiveArrayCritical(jSession, nSession, <span class="number">0</span>);
    nSession = <span class="literal">NULL</span>;

    <span class="comment">// 创建native版本的audiotrack</span>
    sp&lt;AudioTrack&gt; lpTrack = <span class="keyword">new</span> AudioTrack();

    <span class="keyword">audio_attributes_t</span> *paa = <span class="literal">NULL</span>;
    <span class="comment">// 初始化native的attribute。接下来基本上是从java的attribute搬到native的attribute中来。</span>
    paa = (<span class="keyword">audio_attributes_t</span> *) <span class="built_in">calloc</span>(<span class="number">1</span>, <span class="keyword">sizeof</span>(<span class="keyword">audio_attributes_t</span>));
    <span class="keyword">const</span> jstring jtags =
            (jstring) env-&gt;GetObjectField(jaa, javaAudioAttrFields.fieldFormattedTags);
    <span class="keyword">const</span> <span class="keyword">char</span>* tags = env-&gt;GetStringUTFChars(jtags, <span class="literal">NULL</span>);
    <span class="comment">// copying array size -1, char array for tags was calloc'd, no need to NULL-terminate it</span>
    <span class="built_in">strncpy</span>(paa-&gt;tags, tags, AUDIO_ATTRIBUTES_TAGS_MAX_SIZE - <span class="number">1</span>);
    env-&gt;ReleaseStringUTFChars(jtags, tags);
    paa-&gt;usage = (<span class="keyword">audio_usage_t</span>) env-&gt;GetIntField(jaa, javaAudioAttrFields.fieldUsage);
    paa-&gt;content_type =
            (<span class="keyword">audio_content_type_t</span>) env-&gt;GetIntField(jaa, javaAudioAttrFields.fieldContentType);
    paa-&gt;flags = env-&gt;GetIntField(jaa, javaAudioAttrFields.fieldFlags);

    <span class="comment">// initialize the callback information:</span>
    <span class="comment">// this data will be passed with every AudioTrack callback</span>
    <span class="comment">// 初始化callback信息，这个数据将被传递通过audiotrack的callback</span>
    AudioTrackJniStorage* lpJniStorage = <span class="keyword">new</span> AudioTrackJniStorage();
    lpJniStorage-&gt;mCallbackData.audioTrack_class = (jclass)env-&gt;NewGlobalRef(clazz);
    <span class="comment">// 这边使用弱引用，这样audiotrack才能被垃圾回收给回收。</span>
    lpJniStorage-&gt;mCallbackData.audioTrack_ref = env-&gt;NewGlobalRef(weak_this);
    lpJniStorage-&gt;mCallbackData.busy = <span class="literal">false</span>;

    <span class="comment">// 初始化native的audiotrack</span>
    <span class="keyword">status_t</span> status = NO_ERROR;
    <span class="keyword">switch</span> (memoryMode) {
    <span class="comment">// 加载模式是stream</span>
    <span class="keyword">case</span> MODE_STREAM:

        status = lpTrack-&gt;<span class="built_in">set</span>(
                AUDIO_STREAM_DEFAULT,<span class="comment">// stream type, 更多的信息会通过paa来传递。</span>
                sampleRateInHertz,
                format,<span class="comment">// word length, PCM</span>
                nativeChannelMask,
                frameCount,
                AUDIO_OUTPUT_FLAG_NONE,
                audioCallback, &amp;(lpJniStorage-&gt;mCallbackData),<span class="comment">//callback, callback data (user)</span>
                <span class="number">0</span>,<span class="comment">// notificationFrames == 0 因为没有使用EVENT_MORE_DATA来给audiotrack填充数据</span>
                <span class="number">0</span>,<span class="comment">// shared mem</span>
                <span class="literal">true</span>,<span class="comment">// thread can call Java</span>
                sessionId,<span class="comment">// audio session ID</span>
                AudioTrack::TRANSFER_SYNC,
                <span class="literal">NULL</span>,                         <span class="comment">// default offloadInfo</span>
                -<span class="number">1</span>, -<span class="number">1</span>,                       <span class="comment">// default uid, pid values</span>
                paa);
        <span class="keyword">break</span>;
    <span class="comment">// 加载模式为static</span>
    <span class="keyword">case</span> MODE_STATIC:
        <span class="comment">// AudioTrack使用shared memory</span>
        <span class="comment">// 这部分 我们后面在另作分析</span>
        <span class="keyword">if</span> (!lpJniStorage-&gt;allocSharedMem(buffSizeInBytes)) {
            <span class="keyword">goto</span> native_init_failure;
        }

        status = lpTrack-&gt;<span class="built_in">set</span>(
                AUDIO_STREAM_DEFAULT,<span class="comment">// stream type, but more info conveyed in paa (last argument)</span>
                sampleRateInHertz,
                format,<span class="comment">// word length, PCM</span>
                nativeChannelMask,
                frameCount,
                AUDIO_OUTPUT_FLAG_NONE,
                audioCallback, &amp;(lpJniStorage-&gt;mCallbackData),<span class="comment">//callback, callback data (user));</span>
                <span class="number">0</span>,<span class="comment">// notificationFrames == 0 since not using EVENT_MORE_DATA to feed the AudioTrack</span>
                lpJniStorage-&gt;mMemBase,<span class="comment">// shared mem</span>
                <span class="literal">true</span>,<span class="comment">// thread can call Java</span>
                sessionId,<span class="comment">// audio session ID</span>
                AudioTrack::TRANSFER_SHARED,
                <span class="literal">NULL</span>,                         <span class="comment">// default offloadInfo</span>
                -<span class="number">1</span>, -<span class="number">1</span>,                       <span class="comment">// default uid, pid values</span>
                paa);
        <span class="keyword">break</span>;

    <span class="keyword">default</span>:
        <span class="keyword">goto</span> native_init_failure;
    }

    <span class="keyword">if</span> (status != NO_ERROR) {
        <span class="keyword">goto</span> native_init_failure;
    }

    nSession = (jint *) env-&gt;GetPrimitiveArrayCritical(jSession, <span class="literal">NULL</span>);
    <span class="keyword">if</span> (nSession == <span class="literal">NULL</span>) {
        <span class="keyword">goto</span> native_init_failure;
    }
    <span class="comment">// 从audiotrack那边读取sessionid，防止我们创建了个新的session</span>
    nSession[<span class="number">0</span>] = lpTrack-&gt;getSessionId();
    env-&gt;ReleasePrimitiveArrayCritical(jSession, nSession, <span class="number">0</span>);
    nSession = <span class="literal">NULL</span>;

    {   <span class="comment">// scope for the lock</span>
        Mutex::<span class="function">Autolock <span class="title">l</span><span class="params">(sLock)</span></span>;
        <span class="comment">// 将这次的lpJniStorage-&gt;mCallbackData添加到全局的sAudioTrackCallBackCookies数组中</span>
        sAudioTrackCallBackCookies.add(&amp;lpJniStorage-&gt;mCallbackData);
    }

    <span class="comment">// 将native的audiotrack赋值被java的audiotrack类中的变量mNativeTrackInJavaObj</span>
    setAudioTrack(env, thiz, lpTrack);

    <span class="comment">// save the JNI resources so we can free them later</span>
    <span class="comment">// 保存jni的资源，这样我们后面好释放他们。</span>
    env-&gt;SetLongField(thiz, javaAudioTrackFields.jniData, (jlong)lpJniStorage);

    <span class="comment">// 既然我们已经有了audio attributes，stream type是来自于它们，我们将这个值保存回java。</span>
    env-&gt;SetIntField(thiz, javaAudioTrackFields.fieldStreamType, (jint) lpTrack-&gt;streamType());
    <span class="comment">// audio attributes 已经没用了 释放掉。</span>
    <span class="built_in">free</span>(paa);
    paa = <span class="literal">NULL</span>;

    <span class="keyword">return</span> (jint) AUDIO_JAVA_SUCCESS;

<span class="comment">// 创建失败的释放流程。</span>
native_init_failure:
    <span class="keyword">if</span> (paa != <span class="literal">NULL</span>) {
        <span class="built_in">free</span>(paa);
    }
    <span class="keyword">if</span> (nSession != <span class="literal">NULL</span>) {
        env-&gt;ReleasePrimitiveArrayCritical(jSession, nSession, <span class="number">0</span>);
    }
    env-&gt;DeleteGlobalRef(lpJniStorage-&gt;mCallbackData.audioTrack_class);
    env-&gt;DeleteGlobalRef(lpJniStorage-&gt;mCallbackData.audioTrack_ref);
    <span class="keyword">delete</span> lpJniStorage;
    env-&gt;SetLongField(thiz, javaAudioTrackFields.jniData, <span class="number">0</span>);

    <span class="comment">// lpTrack goes out of scope, so reference count drops to zero</span>
    <span class="keyword">return</span> (jint) AUDIOTRACK_ERROR_SETUP_NATIVEINITFAILED;
}
</code></pre><p>该函数主要做了几件事：</p>
<ol>
<li>类型检测、转换，计算framecount，callback信息的记录</li>
<li>创建native的audiotrack</li>
<li>设置audiotrack</li>
</ol>
<p>接下来我们来看audiotrack的设置函数：<code>AudioTrack::set</code></p>
<pre><code><span class="keyword">status_t</span> AudioTrack::<span class="built_in">set</span>(
        <span class="keyword">audio_stream_type_t</span> streamType,
        <span class="keyword">uint32_t</span> sampleRate,
        <span class="keyword">audio_format_t</span> format,
        <span class="keyword">audio_channel_mask_t</span> channelMask,
        <span class="keyword">size_t</span> frameCount,
        <span class="keyword">audio_output_flags_t</span> flags,
        <span class="keyword">callback_t</span> cbf,
        <span class="keyword">void</span>* user,
        <span class="keyword">uint32_t</span> notificationFrames, <span class="comment">// 这个为0</span>
        <span class="keyword">const</span> sp&lt;IMemory&gt;&amp; sharedBuffer, <span class="comment">// 这个为0</span>
        <span class="keyword">bool</span> threadCanCallJava,
        <span class="keyword">int</span> sessionId,
        transfer_type transferType,<span class="comment">//TRANSFER_SYNC </span>
        <span class="keyword">const</span> <span class="keyword">audio_offload_info_t</span> *offloadInfo,
        <span class="keyword">int</span> uid,
        <span class="keyword">pid_t</span> pid,
        <span class="keyword">const</span> <span class="keyword">audio_attributes_t</span>* pAttributes,
        <span class="keyword">bool</span> doNotReconnect)
{

    <span class="keyword">switch</span> (transferType) {
    <span class="keyword">case</span> TRANSFER_DEFAULT:
        <span class="keyword">if</span> (sharedBuffer != <span class="number">0</span>) {
            transferType = TRANSFER_SHARED;
        } <span class="keyword">else</span> <span class="keyword">if</span> (cbf == <span class="literal">NULL</span> || threadCanCallJava) {
            transferType = TRANSFER_SYNC;
        } <span class="keyword">else</span> {
            transferType = TRANSFER_CALLBACK;
        }
        <span class="keyword">break</span>;
    <span class="keyword">case</span> TRANSFER_CALLBACK:
        <span class="keyword">if</span> (cbf == <span class="literal">NULL</span> || sharedBuffer != <span class="number">0</span>) {
            <span class="keyword">return</span> BAD_VALUE;
        }
        <span class="keyword">break</span>;
    <span class="keyword">case</span> TRANSFER_OBTAIN:
    <span class="keyword">case</span> TRANSFER_SYNC:
        <span class="comment">// 要求sharedBuffer必须为0</span>
        <span class="keyword">if</span> (sharedBuffer != <span class="number">0</span>) {
            <span class="keyword">return</span> BAD_VALUE;
        }
        <span class="keyword">break</span>;
    <span class="keyword">case</span> TRANSFER_SHARED:
        <span class="keyword">if</span> (sharedBuffer == <span class="number">0</span>) {
            <span class="keyword">return</span> BAD_VALUE;
        }
        <span class="keyword">break</span>;
    <span class="keyword">default</span>:
        <span class="keyword">return</span> BAD_VALUE;
    }
    mSharedBuffer = sharedBuffer;
    mTransfer = transferType;
    mDoNotReconnect = doNotReconnect;

    <span class="comment">// mAudioTrack != 0为true，只有在成功跑完set之后才会成立。</span>
    <span class="keyword">if</span> (mAudioTrack != <span class="number">0</span>) {
        <span class="keyword">return</span> INVALID_OPERATION;
    }

    <span class="comment">// handle default values first.</span>
    <span class="keyword">if</span> (streamType == AUDIO_STREAM_DEFAULT) {
        streamType = AUDIO_STREAM_MUSIC;
    }
    <span class="keyword">if</span> (pAttributes == <span class="literal">NULL</span>) {
        <span class="keyword">if</span> (<span class="keyword">uint32_t</span>(streamType) &gt;= AUDIO_STREAM_PUBLIC_CNT) {
            <span class="keyword">return</span> BAD_VALUE;
        }
        mStreamType = streamType;

    } <span class="keyword">else</span> {
        <span class="comment">// 拷贝属性，并且设置mStreamType为默认值，stream type不用去看，因为有audio attribute</span>
        <span class="built_in">memcpy</span>(&amp;mAttributes, pAttributes, <span class="keyword">sizeof</span>(<span class="keyword">audio_attributes_t</span>));
        mStreamType = AUDIO_STREAM_DEFAULT;
        <span class="keyword">if</span> ((mAttributes.flags &amp; AUDIO_FLAG_HW_AV_SYNC) != <span class="number">0</span>) {
            flags = (<span class="keyword">audio_output_flags_t</span>)(flags | AUDIO_OUTPUT_FLAG_HW_AV_SYNC);
        }
    }

    <span class="comment">// these below should probably come from the audioFlinger too...</span>
    <span class="comment">// 下面的这些应该可能来自AudioFlinger。</span>
    <span class="keyword">if</span> (format == AUDIO_FORMAT_DEFAULT) {
        format = AUDIO_FORMAT_PCM_16_BIT;
    }

    <span class="comment">// validate parameters</span>
    <span class="keyword">if</span> (!audio_is_valid_format(format)) {
        <span class="keyword">return</span> BAD_VALUE;
    }
    mFormat = format;

    <span class="keyword">if</span> (!audio_is_output_channel(channelMask)) {
        <span class="keyword">return</span> BAD_VALUE;
    }
    mChannelMask = channelMask;
    <span class="keyword">uint32_t</span> channelCount = audio_channel_count_from_out_mask(channelMask);
    mChannelCount = channelCount;

    <span class="comment">// 如果format不是一个线性PCM或者要求是offload的话，则强制打上direct flag。</span>
    <span class="keyword">if</span> ((flags &amp; AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD)
            || !audio_is_linear_pcm(format)) {
        flags = (<span class="keyword">audio_output_flags_t</span>)
                <span class="comment">// fast跟direct不能共存。fast在mixer线程，direct在direct线程</span>
                ((flags | AUDIO_OUTPUT_FLAG_DIRECT) &amp; ~AUDIO_OUTPUT_FLAG_FAST);
    }

    <span class="comment">// 如果要求音视频同步，也强制打上direct flag</span>
    <span class="keyword">if</span> ((flags &amp; AUDIO_OUTPUT_FLAG_HW_AV_SYNC) != <span class="number">0</span>) {
        flags = (<span class="keyword">audio_output_flags_t</span>)(flags | AUDIO_OUTPUT_FLAG_DIRECT);
    }

    <span class="keyword">if</span> (flags &amp; AUDIO_OUTPUT_FLAG_DIRECT) {
        <span class="comment">// 如果是含有direct flag，并且是线性pcm的话，我们需要根据fomat和channelCount来计算帧大小</span>
        <span class="comment">// 否则，如果不是线性pcm的话，那帧大小设置为1个字节，8位。</span>
        <span class="keyword">if</span> (audio_is_linear_pcm(format)) {
            mFrameSize = <span class="function">channelCount * <span class="title">audio_bytes_per_sample</span><span class="params">(format)</span></span>;
        } <span class="keyword">else</span> {
            mFrameSize = <span class="keyword">sizeof</span>(<span class="keyword">uint8_t</span>);
        }
    } <span class="keyword">else</span> {
        <span class="comment">// 非direct的话，那计算就按照线性PCM的方式计算。</span>
        ALOG_ASSERT(audio_is_linear_pcm(format));
        mFrameSize = <span class="function">channelCount * <span class="title">audio_bytes_per_sample</span><span class="params">(format)</span></span>;
        <span class="comment">// 如果PCM format不被AudioFlinger所支持的话，则会在createTrack中返回一个错误，</span>
        <span class="comment">// 所以我们这边不需要特意去检测format。</span>
    }

    <span class="comment">// 对于带有direct flag的track，需要指定samplingRate。</span>
    <span class="keyword">if</span> (sampleRate == <span class="number">0</span> &amp;&amp; (flags &amp; AUDIO_OUTPUT_FLAG_DIRECT) != <span class="number">0</span>) {
        <span class="keyword">return</span> BAD_VALUE;
    }
    mSampleRate = sampleRate;
    mOriginalSampleRate = sampleRate;
    mPlaybackRate = AUDIO_PLAYBACK_RATE_DEFAULT;

    <span class="comment">// Make copy of input parameter offloadInfo so that in the future:</span>
    <span class="comment">//  (a) createTrack_l doesn't need it as an input parameter</span>
    <span class="comment">//  (b) we can support re-creation of offloaded tracks</span>
    <span class="keyword">if</span> (offloadInfo != <span class="literal">NULL</span>) {
        mOffloadInfoCopy = *offloadInfo;
        mOffloadInfo = &amp;mOffloadInfoCopy;
    } <span class="keyword">else</span> {
        mOffloadInfo = <span class="literal">NULL</span>;
    }

    mVolume[AUDIO_INTERLEAVE_LEFT] = <span class="number">1.0f</span>;
    mVolume[AUDIO_INTERLEAVE_RIGHT] = <span class="number">1.0f</span>;
    mSendLevel = <span class="number">0.0f</span>;
    <span class="comment">// mFrameCount在createTrack_l中被初始化</span>
    mReqFrameCount = frameCount;
    mNotificationFramesReq = notificationFrames;
    mNotificationFramesAct = <span class="number">0</span>;
    <span class="comment">// sessionId如果为0，则表示需要系统帮忙分配。</span>
    <span class="keyword">if</span> (sessionId == AUDIO_SESSION_ALLOCATE) {
        mSessionId = AudioSystem::newAudioUniqueId();
    } <span class="keyword">else</span> {
        mSessionId = sessionId;
    }
    <span class="keyword">int</span> callingpid = IPCThreadState::self()-&gt;getCallingPid();
    <span class="keyword">int</span> mypid = getpid();
    <span class="keyword">if</span> (uid == -<span class="number">1</span> || (callingpid != mypid)) {
        mClientUid = IPCThreadState::self()-&gt;getCallingUid();
    } <span class="keyword">else</span> {
        mClientUid = uid;
    }
    <span class="keyword">if</span> (pid == -<span class="number">1</span> || (callingpid != mypid)) {
        mClientPid = callingpid;
    } <span class="keyword">else</span> {
        mClientPid = pid;
    }
    mAuxEffectId = <span class="number">0</span>;
    mFlags = flags;
    mCbf = cbf;
    <span class="comment">// java调用下来的，这边cbf是不为null的。所以java创建的audiotrack都是会创建AudioTrackThread的</span>
    <span class="keyword">if</span> (cbf != <span class="literal">NULL</span>) {
        mAudioTrackThread = <span class="keyword">new</span> AudioTrackThread(*<span class="keyword">this</span>, threadCanCallJava);
        mAudioTrackThread-&gt;run(<span class="string">"AudioTrack"</span>, ANDROID_PRIORITY_AUDIO, <span class="number">0</span> <span class="comment">/*stack*/</span>);
        <span class="comment">// 线程一开始会被paused状态所暂停，直到我们调用了start函数</span>
    }

    <span class="comment">// 创建binder IAudioTrack</span>
    <span class="keyword">status_t</span> status = createTrack_l();
    <span class="comment">// 如果出现问题，则销毁mAudioTrackThread</span>
    <span class="keyword">if</span> (status != NO_ERROR) {
        <span class="keyword">if</span> (mAudioTrackThread != <span class="number">0</span>) {
            mAudioTrackThread-&gt;requestExit();   <span class="comment">// see comment in AudioTrack.h</span>
            mAudioTrackThread-&gt;requestExitAndWait();
            mAudioTrackThread.clear();
        }
        <span class="keyword">return</span> status;
    }

    mStatus = NO_ERROR;
    mState = STATE_STOPPED;
    mUserData = user;
    mLoopCount = <span class="number">0</span>;
    mLoopStart = <span class="number">0</span>;
    mLoopEnd = <span class="number">0</span>;
    mLoopCountNotified = <span class="number">0</span>;
    mMarkerPosition = <span class="number">0</span>;
    mMarkerReached = <span class="literal">false</span>;
    mNewPosition = <span class="number">0</span>;
    mUpdatePeriod = <span class="number">0</span>;
    mPosition = <span class="number">0</span>;
    mReleased = <span class="number">0</span>;
    mStartUs = <span class="number">0</span>;
    <span class="comment">// 这个函数会在AudioFlinger中创建AudioSessionRef对象，并且进行保存。</span>
    AudioSystem::acquireAudioSessionId(mSessionId, mClientPid);
    mSequence = <span class="number">1</span>;
    mObservedSequence = mSequence;
    mInUnderrun = <span class="literal">false</span>;
    mPreviousTimestampValid = <span class="literal">false</span>;
    mTimestampStartupGlitchReported = <span class="literal">false</span>;
    mRetrogradeMotionReported = <span class="literal">false</span>;

    <span class="keyword">return</span> NO_ERROR;
}
</code></pre><p>上面的函数主要干了几件事：</p>
<ol>
<li>对参数的转换和检验，主要是对flag的特殊处理，并且保存了一些数据</li>
<li>audiotrack的回调线程的创建和运行</li>
<li>创建IAudioTrack，这是个binder对象，这个对象是audiotrack在AudioFlinger的代理</li>
<li>acquireAudioSessionId的调用，会在AudioFlinger中对sessionid进行记录。</li>
</ol>
<p>我们来看下关键性函数：<code>createTrack_l</code></p>
<pre><code><span class="keyword">status_t</span> AudioTrack::createTrack_l()
{
    <span class="comment">// 这个我们上面已经看过了，获取AudioFlinger binder对象。</span>
    <span class="keyword">const</span> sp&lt;IAudioFlinger&gt;&amp; audioFlinger = AudioSystem::get_audio_flinger();
    <span class="keyword">if</span> (audioFlinger == <span class="number">0</span>) {
        <span class="keyword">return</span> NO_INIT;
    }
    <span class="comment">// 这个需要在set函数调用之前，通过addAudioDeviceCallback进行设置。</span>
    <span class="keyword">if</span> (mDeviceCallback != <span class="number">0</span> &amp;&amp; mOutput != AUDIO_IO_HANDLE_NONE) {
        AudioSystem::removeAudioDeviceCallback(mDeviceCallback, mOutput);
    }
    <span class="keyword">audio_io_handle_t</span> output;
    <span class="keyword">audio_stream_type_t</span> streamType = mStreamType;
    <span class="comment">// 有属性就会选择属性，这个做法是为了兼容老版本没有属性的时候</span>
    <span class="keyword">audio_attributes_t</span> *attr = (mStreamType == AUDIO_STREAM_DEFAULT) ? &amp;mAttributes : <span class="literal">NULL</span>;

    <span class="keyword">status_t</span> status;
    <span class="comment">// 获取output的操作，从函数名字可以知道是根据attribute来获取。</span>
    status = AudioSystem::getOutputForAttr(attr, &amp;output,
                                           (<span class="keyword">audio_session_t</span>)mSessionId, &amp;streamType, mClientUid,
                                           mSampleRate, mFormat, mChannelMask,
                                           mFlags, mSelectedDeviceId, mOffloadInfo);
    <span class="comment">// 获取失败</span>
    <span class="keyword">if</span> (status != NO_ERROR || output == AUDIO_IO_HANDLE_NONE) {
        <span class="keyword">return</span> BAD_VALUE;
    }
    <span class="comment">// 获取成功</span>
    {
    <span class="comment">// 由于上面获取output成功的话，则会在AudioPolicy那边注册mOutputRoutes，并且对于direct output</span>
    <span class="comment">// 如果获取到的是已经创建过的，则会增加引用计数。</span>
    <span class="comment">// 但是我们还没用通过这个io索引去跟AudioFlinger交互，尚未被登记到AudioFlinger，</span>
    <span class="comment">// 如果该track被登记到AudioFlinger，AudioFlinger就会维护output的信息，但是我们目前没有注册过去</span>
    <span class="comment">// 所以下面我们一旦有出错，我们必须自己手动释放掉该output。</span>

    <span class="comment">// 获取output的latency</span>
    status = AudioSystem::getLatency(output, &amp;mAfLatency);
    <span class="keyword">if</span> (status != NO_ERROR) {
        <span class="keyword">goto</span> release;
    }
    <span class="comment">// 获取output的mAfFrameCount</span>
    status = AudioSystem::getFrameCount(output, &amp;mAfFrameCount);
    <span class="keyword">if</span> (status != NO_ERROR) {
        <span class="keyword">goto</span> release;
    }
    <span class="comment">// 获取output的mAfSampleRate</span>
    status = AudioSystem::getSamplingRate(output, &amp;mAfSampleRate);
    <span class="keyword">if</span> (status != NO_ERROR) {
        <span class="keyword">goto</span> release;
    }
    <span class="comment">// 如果之前没有设置采样率，则使用该output当前的采样率</span>
    <span class="keyword">if</span> (mSampleRate == <span class="number">0</span>) {
        mSampleRate = mAfSampleRate;
        mOriginalSampleRate = mAfSampleRate;
    }
    <span class="comment">// Client decides whether the track is TIMED (see below), but can only express a preference</span>
    <span class="comment">// for FAST.  Server will perform additional tests.</span>
    <span class="comment">// 如果你想采用FAST模式，那你只能用共享内存，或者Callback、TRANSFER_OBTAIN的形式，并且必须保证</span>
    <span class="comment">// 采样率跟对应的output一致才行。这个是client端这边的要求，server端也有要求。</span>
    <span class="keyword">if</span> ((mFlags &amp; AUDIO_OUTPUT_FLAG_FAST) &amp;&amp; !((
            (mSharedBuffer != <span class="number">0</span>) ||
            (mTransfer == TRANSFER_CALLBACK) ||
            (mTransfer == TRANSFER_OBTAIN)) &amp;&amp;
            (mSampleRate == mAfSampleRate))) {
        <span class="comment">// once denied, do not request again if IAudioTrack is re-created</span>
        mFlags = (<span class="keyword">audio_output_flags_t</span>) (mFlags &amp; ~AUDIO_OUTPUT_FLAG_FAST);
    }

    <span class="comment">// The client's AudioTrack buffer is divided into n parts for purpose of wakeup by server, where</span>
    <span class="comment">// client端的audiotrack的buffer被分成几部分，server端根据这个来唤醒client填充数据</span>
    <span class="comment">//  n = 1   fast track with single buffering; nBuffering is ignored</span>
    <span class="comment">//  n = 2   fast track with double buffering</span>
    <span class="comment">//  n = 2   normal track, (including those with sample rate conversion)</span>
    <span class="comment">//  n &gt;= 3  very high latency or very small notification interval (unused).</span>
    <span class="keyword">const</span> <span class="keyword">uint32_t</span> nBuffering = <span class="number">2</span>;

    mNotificationFramesAct = mNotificationFramesReq;
    <span class="comment">// mReqFrameCount这个就是app申请的大小</span>
    <span class="keyword">size_t</span> frameCount = mReqFrameCount;
    <span class="comment">// 如果不是线性pcm的话，并且采用share memory则获取share memory的size，不是采用share memory并</span>
    <span class="comment">// 且framecount为0， 则用hal的framecount， 如果mNotificationFramesAct不等于framecount，则用</span>
    <span class="comment">// framecount赋值给mNotificationFramesAct</span>
    <span class="comment">// 如果是线性pcm的话，如果采用的是share memory，先不说了。。。。</span>
    <span class="comment">// 如果是线性pcm的话，不是采用share memory，对于非fast track，会先计算下所需要的</span>
    <span class="comment">// calculateMinFrameCount，这边用的是获取到的值就有参考意义了，因为这边的output获取的是最后会</span>
    <span class="comment">// 用来播放output thread。</span>
    <span class="keyword">if</span> (!audio_is_linear_pcm(mFormat)) {

        <span class="keyword">if</span> (mSharedBuffer != <span class="number">0</span>) {
            <span class="comment">// Same comment as below about ignoring frameCount parameter for set()</span>
            frameCount = mSharedBuffer-&gt;size();
        } <span class="keyword">else</span> <span class="keyword">if</span> (frameCount == <span class="number">0</span>) {
            frameCount = mAfFrameCount;
        }
        <span class="keyword">if</span> (mNotificationFramesAct != frameCount) {
            mNotificationFramesAct = frameCount;
        }
    } <span class="keyword">else</span> <span class="keyword">if</span> (mSharedBuffer != <span class="number">0</span>) {
        <span class="comment">// <span class="doctag">FIXME:</span> Ensure client side memory buffers need</span>
        <span class="comment">// not have additional alignment beyond sample</span>
        <span class="comment">// (e.g. 16 bit stereo accessed as 32 bit frame).</span>
        <span class="keyword">size_t</span> alignment = audio_bytes_per_sample(mFormat);
        <span class="keyword">if</span> (alignment &amp; <span class="number">1</span>) {
            <span class="comment">// for AUDIO_FORMAT_PCM_24_BIT_PACKED (not exposed through Java).</span>
            alignment = <span class="number">1</span>;
        }
        <span class="keyword">if</span> (mChannelCount &gt; <span class="number">1</span>) {
            <span class="comment">// More than 2 channels does not require stronger alignment than stereo</span>
            alignment &lt;&lt;= <span class="number">1</span>;
        }
        <span class="keyword">if</span> (((<span class="keyword">uintptr_t</span>)mSharedBuffer-&gt;pointer() &amp; (alignment - <span class="number">1</span>)) != <span class="number">0</span>) {
            status = BAD_VALUE;
            <span class="keyword">goto</span> release;
        }

        <span class="comment">// When initializing a shared buffer AudioTrack via constructors,</span>
        <span class="comment">// there's no frameCount parameter.</span>
        <span class="comment">// But when initializing a shared buffer AudioTrack via set(),</span>
        <span class="comment">// there _is_ a frameCount parameter.  We silently ignore it.</span>
        frameCount = mSharedBuffer-&gt;size() / mFrameSize;
    } <span class="keyword">else</span> {
        <span class="comment">// 对于fast tracks framecount是在server端进行计算和检测的。</span>

        <span class="keyword">if</span> ((mFlags &amp; AUDIO_OUTPUT_FLAG_FAST) == <span class="number">0</span>) {
            <span class="comment">// 对于普通的tracks，之前计算是基于速度的。</span>
            <span class="keyword">const</span> <span class="keyword">size_t</span> minFrameCount = calculateMinFrameCount(
                    mAfLatency, mAfFrameCount, mAfSampleRate, mSampleRate,
                    mPlaybackRate.mSpeed);
            <span class="keyword">if</span> (frameCount &lt; minFrameCount) {
                frameCount = minFrameCount;
            }
        }
    }

    IAudioFlinger::<span class="keyword">track_flags_t</span> trackFlags = IAudioFlinger::TRACK_DEFAULT;
    <span class="comment">// 如果是timetrack的话，加上TRACK_TIMED</span>
    <span class="keyword">if</span> (mIsTimed) {
        trackFlags |= IAudioFlinger::TRACK_TIMED;
    }

    <span class="keyword">pid_t</span> tid = -<span class="number">1</span>;
    <span class="keyword">if</span> (mFlags &amp; AUDIO_OUTPUT_FLAG_FAST) {
        trackFlags |= IAudioFlinger::TRACK_FAST;
        <span class="keyword">if</span> (mAudioTrackThread != <span class="number">0</span>) {
            tid = mAudioTrackThread-&gt;getTid();
        }
    }

    <span class="keyword">if</span> (mFlags &amp; AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) {
        trackFlags |= IAudioFlinger::TRACK_OFFLOAD;
    }

    <span class="keyword">if</span> (mFlags &amp; AUDIO_OUTPUT_FLAG_DIRECT) {
        trackFlags |= IAudioFlinger::TRACK_DIRECT;
    }

    <span class="keyword">size_t</span> temp = frameCount;   <span class="comment">// temp may be replaced by a revised value of frameCount,</span>
                                <span class="comment">// but we will still need the original value also</span>
    <span class="keyword">int</span> originalSessionId = mSessionId;
    <span class="comment">// 这个函数后面拉出来分析</span>
    sp&lt;IAudioTrack&gt; track = audioFlinger-&gt;createTrack(streamType,
                                                      mSampleRate,
                                                      mFormat,
                                                      mChannelMask,
                                                      &amp;temp,
                                                      &amp;trackFlags,
                                                      mSharedBuffer,
                                                      output,
                                                      tid,
                                                      &amp;mSessionId,
                                                      mClientUid,
                                                      &amp;status);

    <span class="keyword">if</span> (status != NO_ERROR) {
        <span class="keyword">goto</span> release;
    }
    ALOG_ASSERT(track != <span class="number">0</span>);

    <span class="comment">// 通过AudioFlinger去创建track之后，AudioFlinger就已经拥有I/O handle的引用了</span>
    <span class="comment">// 所以我们就不用再去负责释放handle的释放问题了。</span>

    sp&lt;IMemory&gt; iMem = track-&gt;getCblk();
    <span class="keyword">if</span> (iMem == <span class="number">0</span>) {
        <span class="keyword">return</span> NO_INIT;
    }
    <span class="keyword">void</span> *iMemPointer = iMem-&gt;pointer();
    <span class="keyword">if</span> (iMemPointer == <span class="literal">NULL</span>) {
        <span class="keyword">return</span> NO_INIT;
    }
    <span class="comment">// 只有set成功之后，mAudioTrack才不为0，这边先释放mDeathNotifier</span>
    <span class="keyword">if</span> (mAudioTrack != <span class="number">0</span>) {
        IInterface::asBinder(mAudioTrack)-&gt;unlinkToDeath(mDeathNotifier, <span class="keyword">this</span>);
        mDeathNotifier.clear();
    }
    mAudioTrack = track;
    mCblkMemory = iMem;
    IPCThreadState::self()-&gt;flushCommands();

    <span class="keyword">audio_track_cblk_t</span>* cblk = <span class="keyword">static_cast</span>&lt;<span class="keyword">audio_track_cblk_t</span>*&gt;(iMemPointer);
    mCblk = cblk;
    <span class="comment">// temp可能是被修改过了。如果被修改的话，只可能变大。</span>
    <span class="keyword">if</span> (temp &lt; frameCount || (frameCount == <span class="number">0</span> &amp;&amp; temp == <span class="number">0</span>)) {
        <span class="comment">// 在当前这种设计，AudioTrack这边会先检查并且确认这个值是有效的才会传递给AudioFlinger，所</span>
        <span class="comment">// 以AudioFlinger是不会返回一个不一样的值的，除了fast track，它使用的是一个特殊的方法来指</span>
        <span class="comment">// 定frame count</span>
        ALOGW(<span class="string">"Requested frameCount %zu but received frameCount %zu"</span>, frameCount, temp);
    }
    frameCount = temp;

    <span class="comment">// 是否等待线程的优先级设置成功了。这个是针对fast track的变量</span>
    mAwaitBoost = <span class="literal">false</span>;
    <span class="keyword">if</span> (mFlags &amp; AUDIO_OUTPUT_FLAG_FAST) {
        <span class="keyword">if</span> (trackFlags &amp; IAudioFlinger::TRACK_FAST) {
            <span class="comment">// 如果这个track申请fast通过AudioFlinger那边的审查之后，就需要等待线程优先级设置了。</span>
            mAwaitBoost = <span class="literal">true</span>;
        } <span class="keyword">else</span> {
            <span class="comment">// once denied, do not request again if IAudioTrack is re-created</span>
            <span class="comment">// 将该标志移除，只要失败一次，下次re-created的话也不会再触发fast的判断了。</span>
            mFlags = (<span class="keyword">audio_output_flags_t</span>) (mFlags &amp; ~AUDIO_OUTPUT_FLAG_FAST);
        }
    }
    <span class="keyword">if</span> (mFlags &amp; AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) {
        <span class="keyword">if</span> (trackFlags &amp; IAudioFlinger::TRACK_OFFLOAD) {
            ALOGV(<span class="string">"AUDIO_OUTPUT_FLAG_OFFLOAD successful"</span>);
        } <span class="keyword">else</span> {
            <span class="comment">// 申请offload失败</span>
            mFlags = (<span class="keyword">audio_output_flags_t</span>) (mFlags &amp; ~AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD);
        }
    }
    <span class="keyword">if</span> (mFlags &amp; AUDIO_OUTPUT_FLAG_DIRECT) {
        <span class="keyword">if</span> (trackFlags &amp; IAudioFlinger::TRACK_DIRECT) {
            ALOGV(<span class="string">"AUDIO_OUTPUT_FLAG_DIRECT successful"</span>);
        } <span class="keyword">else</span> {
            mFlags = (<span class="keyword">audio_output_flags_t</span>) (mFlags &amp; ~AUDIO_OUTPUT_FLAG_DIRECT);
        }
    }
    <span class="comment">// Make sure that application is notified with sufficient margin before underrun</span>
    <span class="comment">// 确保及时问app要数据，在buffer内还有不少数据的情况下，防止出现underrun</span>
    <span class="keyword">if</span> (mSharedBuffer == <span class="number">0</span> &amp;&amp; audio_is_linear_pcm(mFormat)) {
        <span class="comment">// Theoretically double-buffering is not required for fast tracks,</span>
        <span class="comment">// due to tighter scheduling.  But in practice, to accommodate kernels with</span>
        <span class="comment">// scheduling jitter, and apps with computation jitter, we use double-buffering</span>
        <span class="comment">// for fast tracks just like normal streaming tracks.</span>
        <span class="comment">// 确定消费了多少帧可以唤醒audiotrack来填充数据。</span>
        <span class="keyword">if</span> (mNotificationFramesAct == <span class="number">0</span> || mNotificationFramesAct &gt; frameCount / nBuffering) {
            mNotificationFramesAct = frameCount / nBuffering;
        }
    }

    <span class="comment">// We retain a copy of the I/O handle, but don't own the reference</span>
    mOutput = output;
    mRefreshRemaining = <span class="literal">true</span>;
    <span class="comment">// 确定buffer的地址，对于非share memory的话，在cblk下面。</span>
    <span class="keyword">void</span>* buffers;
    <span class="keyword">if</span> (mSharedBuffer == <span class="number">0</span>) {
        buffers = cblk + <span class="number">1</span>;
    } <span class="keyword">else</span> {
        buffers = mSharedBuffer-&gt;pointer();
        <span class="keyword">if</span> (buffers == <span class="literal">NULL</span>) {
            ALOGE(<span class="string">"Could not get buffer pointer"</span>);
            <span class="keyword">return</span> NO_INIT;
        }
    }
    <span class="comment">// 这部分后面再做补充吧。关于AuxEffect</span>
    mAudioTrack-&gt;attachAuxEffect(mAuxEffectId);
    <span class="comment">// 如果申请OFFLAOD成功的话，latency采用hal的latency，否则我们自己计算一个latency</span>
    <span class="keyword">if</span> (mFlags &amp; AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) {
        <span class="comment">// Use latency given by HAL in offload mode</span>
        mLatency = mAfLatency;
    } <span class="keyword">else</span> {
        <span class="comment">// FIXME doesn't take into account speed or future sample rate changes (until restoreTrack)</span>
        <span class="comment">// FIXME don't believe this lie</span>
        <span class="comment">// 这个是上层计算的延时，申请的空间所花费时间+hal的latency。</span>
        mLatency = mAfLatency + (<span class="number">1000</span>*frameCount) / mSampleRate;
    }
    mFrameCount = frameCount;

    <span class="comment">// 如果出现IAudioTrack的re-created的话，为了防止分配空间不一致，所以将申请到的空间直接替换用户</span>
    <span class="comment">// 请求的。什么情况下出现re-created的场景？为什么需要如此？</span>
    <span class="keyword">if</span> (frameCount &gt; mReqFrameCount) {
        mReqFrameCount = frameCount;
    }

    <span class="comment">// reset server position to 0 as we have new cblk.</span>
    mServer = <span class="number">0</span>;

    <span class="comment">// 更新proxy</span>
    <span class="keyword">if</span> (mSharedBuffer == <span class="number">0</span>) {
        mStaticProxy.clear();
        mProxy = <span class="keyword">new</span> AudioTrackClientProxy(cblk, buffers, frameCount, mFrameSize);
    } <span class="keyword">else</span> {
        mStaticProxy = <span class="keyword">new</span> StaticAudioTrackClientProxy(cblk, buffers, frameCount, mFrameSize);
        mProxy = mStaticProxy;
    }

    mProxy-&gt;setVolumeLR(gain_minifloat_pack(
            gain_from_float(mVolume[AUDIO_INTERLEAVE_LEFT]),
            gain_from_float(mVolume[AUDIO_INTERLEAVE_RIGHT])));

    mProxy-&gt;setSendLevel(mSendLevel);
    <span class="keyword">const</span> <span class="keyword">uint32_t</span> effectiveSampleRate = adjustSampleRate(mSampleRate, mPlaybackRate.mPitch);
    <span class="keyword">const</span> <span class="keyword">float</span> effectiveSpeed = adjustSpeed(mPlaybackRate.mSpeed, mPlaybackRate.mPitch);
    <span class="keyword">const</span> <span class="keyword">float</span> effectivePitch = adjustPitch(mPlaybackRate.mPitch);
    mProxy-&gt;setSampleRate(effectiveSampleRate);

    AudioPlaybackRate playbackRateTemp = mPlaybackRate;
    playbackRateTemp.mSpeed = effectiveSpeed;
    playbackRateTemp.mPitch = effectivePitch;
    mProxy-&gt;setPlaybackRate(playbackRateTemp);
    <span class="comment">// 将刚才计算出来server端消费多少可以通知app的数值告诉代理。</span>
    mProxy-&gt;setMinimum(mNotificationFramesAct);
    <span class="comment">// 如果IAudioTrack挂掉了，做一些后续工作，让audiotrack不用等待了，并且设置INVALID状态</span>
    mDeathNotifier = <span class="keyword">new</span> DeathNotifier(<span class="keyword">this</span>);
    IInterface::asBinder(mAudioTrack)-&gt;linkToDeath(mDeathNotifier, <span class="keyword">this</span>);

    <span class="keyword">if</span> (mDeviceCallback != <span class="number">0</span>) {
        AudioSystem::addAudioDeviceCallback(mDeviceCallback, mOutput);
    }

    <span class="keyword">return</span> NO_ERROR;
    }

release:
    <span class="comment">// 释放output</span>
    AudioSystem::releaseOutput(output, streamType, (<span class="keyword">audio_session_t</span>)mSessionId);
    <span class="keyword">if</span> (status == NO_ERROR) {
        status = NO_INIT;
    }
    <span class="keyword">return</span> status;
}
</code></pre><p>上面函数主要干了几件事：</p>
<ol>
<li>通过创建的audiotrack的attribute来获取对应的output thread。</li>
<li>针对fast track进行过滤，并且构造track的flag</li>
<li>接下来让AudioFlinger去创建IAudioTrack对象，由于server端也需要检测track类型，所以返回后需要更新audiotrack这边的flag的信息。</li>
<li>通知proxy什么时候可以通知audiotrack填充数据。</li>
</ol>
<p><code>AudioPolicyManager::getOutputForAttr()</code>这个函数的实现跟我们上面加过的<code>getOutput</code>差不多，只是这边传递attribute来获取，并且这次获取的，跟我们本次申请的是一致的。</p>
<p>我们来看AudioFlinger的<code>createTrack</code>的实现</p>
<pre><code>sp&lt;IAudioTrack&gt; AudioFlinger::createTrack(
        <span class="keyword">audio_stream_type_t</span> streamType,
        <span class="keyword">uint32_t</span> sampleRate,
        <span class="keyword">audio_format_t</span> format,
        <span class="keyword">audio_channel_mask_t</span> channelMask,
        <span class="keyword">size_t</span> *frameCount,
        IAudioFlinger::<span class="keyword">track_flags_t</span> *flags,
        <span class="keyword">const</span> sp&lt;IMemory&gt;&amp; sharedBuffer,
        <span class="keyword">audio_io_handle_t</span> output,<span class="comment">// 这个是output的索引</span>
        <span class="keyword">pid_t</span> tid,
        <span class="keyword">int</span> *sessionId,
        <span class="keyword">int</span> clientUid,
        <span class="keyword">status_t</span> *status)
{
    sp&lt;PlaybackThread::Track&gt; track;
    sp&lt;TrackHandle&gt; trackHandle;
    sp&lt;Client&gt; client;
    <span class="keyword">status_t</span> lStatus;
    <span class="keyword">int</span> lSessionId;

    <span class="comment">// client AudioTrack::set already implements AUDIO_STREAM_DEFAULT =&gt; AUDIO_STREAM_MUSIC,</span>
    <span class="comment">// but if someone uses binder directly they could bypass that and cause us to crash</span>
    <span class="keyword">if</span> (<span class="keyword">uint32_t</span>(streamType) &gt;= AUDIO_STREAM_CNT) {
        lStatus = BAD_VALUE;
        <span class="keyword">goto</span> Exit;
    }

    <span class="comment">// further sample rate checks are performed by createTrack_l() depending on the thread type</span>
    <span class="keyword">if</span> (sampleRate == <span class="number">0</span>) {
        lStatus = BAD_VALUE;
        <span class="keyword">goto</span> Exit;
    }

    <span class="comment">// further channel mask checks are performed by createTrack_l() depending on the thread type</span>
    <span class="keyword">if</span> (!audio_is_output_channel(channelMask)) {
        lStatus = BAD_VALUE;
        <span class="keyword">goto</span> Exit;
    }

    <span class="comment">// further format checks are performed by createTrack_l() depending on the thread type</span>
    <span class="keyword">if</span> (!audio_is_valid_format(format)) {
        lStatus = BAD_VALUE;
        <span class="keyword">goto</span> Exit;
    }

    <span class="keyword">if</span> (sharedBuffer != <span class="number">0</span> &amp;&amp; sharedBuffer-&gt;pointer() == <span class="literal">NULL</span>) {
        lStatus = BAD_VALUE;
        <span class="keyword">goto</span> Exit;
    }

    {
        Mutex::Autolock _l(mLock);
        <span class="comment">// 根据output索引获取到output thread对象</span>
        PlaybackThread *thread = checkPlaybackThread_l(output);
        <span class="keyword">if</span> (thread == <span class="literal">NULL</span>) {
            lStatus = BAD_VALUE;
            <span class="keyword">goto</span> Exit;
        }
        <span class="comment">// 这边又注册了一次client。</span>
        <span class="keyword">pid_t</span> pid = IPCThreadState::self()-&gt;getCallingPid();
        client = registerPid(pid);

        PlaybackThread *effectThread = <span class="literal">NULL</span>;
        <span class="keyword">if</span> (sessionId != <span class="literal">NULL</span> &amp;&amp; *sessionId != AUDIO_SESSION_ALLOCATE) {
            lSessionId = *sessionId;
            <span class="comment">// 检测是否有一个相同session id的效果链在另外一个output thread，有的话则移过来。</span>
            <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; mPlaybackThreads.size(); i++) {
                sp&lt;PlaybackThread&gt; t = mPlaybackThreads.valueAt(i);
                <span class="keyword">if</span> (mPlaybackThreads.keyAt(i) != output) {
                    <span class="keyword">uint32_t</span> sessions = t-&gt;hasAudioSession(lSessionId);
                    <span class="keyword">if</span> (sessions &amp; PlaybackThread::EFFECT_SESSION) {
                        effectThread = t.get();
                        <span class="keyword">break</span>;
                    }
                }
            }
        } <span class="keyword">else</span> {
            <span class="comment">// sessionid没有指定，则给自动分配一个</span>
            lSessionId = nextUniqueId();
            <span class="keyword">if</span> (sessionId != <span class="literal">NULL</span>) {
                *sessionId = lSessionId;
            }
        }
        <span class="comment">// 让对应的output thread去创建track</span>
        track = thread-&gt;createTrack_l(client, streamType, sampleRate, format,
                channelMask, frameCount, sharedBuffer, lSessionId, flags, tid, clientUid, &amp;lStatus);
        LOG_ALWAYS_FATAL_IF((lStatus == NO_ERROR) &amp;&amp; (track == <span class="number">0</span>));
        <span class="comment">// we don't abort yet if lStatus != NO_ERROR; there is still work to be done regardless</span>

        <span class="comment">// move effect chain to this output thread if an effect on same session was waiting</span>
        <span class="comment">// for a track to be created</span>
        <span class="comment">// 如果track被创建成功，并且存在effectThread的话，我们就将效果给移过来。</span>
        <span class="keyword">if</span> (lStatus == NO_ERROR &amp;&amp; effectThread != <span class="literal">NULL</span>) {
            <span class="comment">// no risk of deadlock because AudioFlinger::mLock is held</span>
            Mutex::Autolock _dl(thread-&gt;mLock);
            Mutex::Autolock _sl(effectThread-&gt;mLock);
            moveEffectChain_l(lSessionId, effectThread, thread, <span class="literal">true</span>);
        }

        <span class="comment">// Look for sync events awaiting for a session to be used.</span>
        <span class="comment">// 这部分不太清楚作用，后面再看看</span>
        <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; mPendingSyncEvents.size(); i++) {
            <span class="keyword">if</span> (mPendingSyncEvents[i]-&gt;triggerSession() == lSessionId) {
                <span class="keyword">if</span> (thread-&gt;isValidSyncEvent(mPendingSyncEvents[i])) {
                    <span class="keyword">if</span> (lStatus == NO_ERROR) {
                        (<span class="keyword">void</span>) track-&gt;setSyncEvent(mPendingSyncEvents[i]);
                    } <span class="keyword">else</span> {
                        mPendingSyncEvents[i]-&gt;cancel();
                    }
                    mPendingSyncEvents.removeAt(i);
                    i--;
                }
            }
        }

        setAudioHwSyncForSession_l(thread, (<span class="keyword">audio_session_t</span>)lSessionId);
    }

    <span class="keyword">if</span> (lStatus != NO_ERROR) {
        <span class="comment">// remove local strong reference to Client before deleting the Track so that the</span>
        <span class="comment">// Client destructor is called by the TrackBase destructor with mClientLock held</span>
        <span class="comment">// Don't hold mClientLock when releasing the reference on the track as the</span>
        <span class="comment">// destructor will acquire it.</span>
        {
            Mutex::Autolock _cl(mClientLock);
            client.clear();
        }
        track.clear();
        <span class="keyword">goto</span> Exit;
    }

    <span class="comment">// return handle to client</span>
    <span class="comment">// 封装一个binder对象给audiotrack.</span>
    trackHandle = <span class="keyword">new</span> TrackHandle(track);

Exit:
    *status = lStatus;
    <span class="keyword">return</span> trackHandle;
}
</code></pre><p>上面函数主要也是对一些参数的检测,以及确认是否有效果需要转移过来,如果有则转移.<br>这边又对pid注册了一个client在AudioFlinger。<br>但是我们主体逻辑还是在output thread去<code>createTrack_l</code>的。</p>
<pre><code>sp&lt;AudioFlinger::PlaybackThread::Track&gt; AudioFlinger::PlaybackThread::createTrack_l(
        <span class="keyword">const</span> sp&lt;AudioFlinger::Client&gt;&amp; client,
        <span class="keyword">audio_stream_type_t</span> streamType,
        <span class="keyword">uint32_t</span> sampleRate,
        <span class="keyword">audio_format_t</span> format,
        <span class="keyword">audio_channel_mask_t</span> channelMask,
        <span class="keyword">size_t</span> *pFrameCount,
        <span class="keyword">const</span> sp&lt;IMemory&gt;&amp; sharedBuffer,
        <span class="keyword">int</span> sessionId,
        IAudioFlinger::<span class="keyword">track_flags_t</span> *flags,
        <span class="keyword">pid_t</span> tid,
        <span class="keyword">int</span> uid,
        <span class="keyword">status_t</span> *status)
{
    <span class="keyword">size_t</span> frameCount = *pFrameCount;
    sp&lt;Track&gt; track;
    <span class="keyword">status_t</span> lStatus;

    <span class="keyword">bool</span> isTimed = (*flags &amp; IAudioFlinger::TRACK_TIMED) != <span class="number">0</span>;

    <span class="comment">// fast track能否成功最后还是AudioFlinger说的算。</span>
    <span class="keyword">if</span> (*flags &amp; IAudioFlinger::TRACK_FAST) {
        <span class="comment">// 要想通过fast的确认，可以看出要求很严格，首先不能是timeAudioTrack，其次可以是</span>
        <span class="comment">// sharebuffer，或者是有Callback并且申请的framecount大于hal层的framecount，再次，必须是</span>
        <span class="comment">// pcm流，在再次，channel一致或者channel为单声道或者线程不为立体声道，在在再次，采样率一致，</span>
        <span class="comment">// 在在在再次，有关联的fast mixer，在在在在再次，还有坑。。</span>
      <span class="keyword">if</span> (
            <span class="comment">// not timed</span>
            (!isTimed) &amp;&amp;
            <span class="comment">// either of these use cases:</span>
            (
              <span class="comment">// use case 1: shared buffer with any frame count</span>
              (
                (sharedBuffer != <span class="number">0</span>)
              ) ||
              <span class="comment">// use case 2: frame count is default or at least as large as HAL</span>
              (
                <span class="comment">// we formerly checked for a callback handler (non-0 tid),</span>
                <span class="comment">// but that is no longer required for TRANSFER_OBTAIN mode</span>
                ((frameCount == <span class="number">0</span>) ||
                (frameCount &gt;= mFrameCount))
              )
            ) &amp;&amp;
            <span class="comment">// PCM data</span>
            audio_is_linear_pcm(format) &amp;&amp;
            <span class="comment">// <span class="doctag">TODO:</span> extract as a data library function that checks that a computationally</span>
            <span class="comment">// expensive downmixer is not required: isFastOutputChannelConversion()</span>
            (channelMask == mChannelMask ||
                    mChannelMask != AUDIO_CHANNEL_OUT_STEREO ||
                    (channelMask == AUDIO_CHANNEL_OUT_MONO
                            <span class="comment">/* &amp;&amp; mChannelMask == AUDIO_CHANNEL_OUT_STEREO */</span>)) &amp;&amp;
            <span class="comment">// hardware sample rate</span>
            (sampleRate == mSampleRate) &amp;&amp;
            <span class="comment">// 普通mixer线程会有一个关联的fast mixer</span>
            hasFastMixer() &amp;&amp;
            <span class="comment">// there are sufficient fast track slots available</span>
            (mFastTrackAvailMask != <span class="number">0</span>)
            <span class="comment">// FIXME test that MixerThread for this fast track has a capable output HAL</span>
            <span class="comment">// FIXME add a permission test also?</span>
        ) {
        <span class="comment">// if frameCount not specified, then it defaults to fast mixer (HAL) frame count</span>
        <span class="keyword">if</span> (frameCount == <span class="number">0</span>) {
            <span class="comment">// read the fast track multiplier property the first time it is needed</span>
            <span class="keyword">int</span> ok = pthread_once(&amp;sFastTrackMultiplierOnce, sFastTrackMultiplierInit);
            <span class="keyword">if</span> (ok != <span class="number">0</span>) {
                ALOGE(<span class="string">"%s pthread_once failed: %d"</span>, __func__, ok);
            }
            <span class="comment">// 为fast track计算framecount</span>
            frameCount = mFrameCount * sFastTrackMultiplier;
        }
      } <span class="keyword">else</span> {
        *flags &amp;= ~IAudioFlinger::TRACK_FAST;
      }
    }
    <span class="comment">// For normal PCM streaming tracks, update minimum frame count.</span>
    <span class="comment">// For compatibility with AudioTrack calculation, buffer depth is forced</span>
    <span class="comment">// to be at least 2 x the normal mixer frame count and cover audio hardware latency.</span>
    <span class="comment">// This is probably too conservative, but legacy application code may depend on it.</span>
    <span class="comment">// If you change this calculation, also review the start threshold which is related.</span>
    <span class="comment">// 更新最小的framecount，如果framecount小于最低的，则用最低来替换。</span>
    <span class="keyword">if</span> (!(*flags &amp; IAudioFlinger::TRACK_FAST)
            &amp;&amp; audio_is_linear_pcm(format) &amp;&amp; sharedBuffer == <span class="number">0</span>) {
        <span class="comment">// this must match AudioTrack.cpp calculateMinFrameCount().</span>
        <span class="comment">// <span class="doctag">TODO:</span> Move to a common library</span>
        <span class="keyword">uint32_t</span> latencyMs = mOutput-&gt;stream-&gt;get_latency(mOutput-&gt;stream);
        <span class="keyword">uint32_t</span> minBufCount = latencyMs / ((<span class="number">1000</span> * mNormalFrameCount) / mSampleRate);
        <span class="keyword">if</span> (minBufCount &lt; <span class="number">2</span>) {
            minBufCount = <span class="number">2</span>;
        }
        <span class="comment">// For normal mixing tracks, if speed is &gt; 1.0f (normal), AudioTrack</span>
        <span class="comment">// or the client should compute and pass in a larger buffer request.</span>
        <span class="keyword">size_t</span> minFrameCount =
                <span class="function">minBufCount * <span class="title">sourceFramesNeededWithTimestretch</span><span class="params">(
                        sampleRate, mNormalFrameCount,
                        mSampleRate, AUDIO_TIMESTRETCH_SPEED_NORMAL <span class="comment">/*speed*/</span>)</span></span>;
        <span class="keyword">if</span> (frameCount &lt; minFrameCount) { <span class="comment">// including frameCount == 0</span>
            frameCount = minFrameCount;
        }
    }
    *pFrameCount = frameCount;

    <span class="keyword">switch</span> (mType) {
    <span class="comment">// DIRECT 线程 如果是线性PCM, 要求所有的参数都必须符合。</span>
    <span class="keyword">case</span> DIRECT:
        <span class="keyword">if</span> (audio_is_linear_pcm(format)) {
            <span class="keyword">if</span> (sampleRate != mSampleRate || format != mFormat || channelMask != mChannelMask) {
                lStatus = BAD_VALUE;
                <span class="keyword">goto</span> Exit;
            }
        }
        <span class="keyword">break</span>;
    <span class="comment">// OFFLOAD 线程 要求所有的参数必须符合。</span>
    <span class="keyword">case</span> OFFLOAD:
        <span class="keyword">if</span> (sampleRate != mSampleRate || format != mFormat || channelMask != mChannelMask) {
            lStatus = BAD_VALUE;
            <span class="keyword">goto</span> Exit;
        }
        <span class="keyword">break</span>;

    <span class="keyword">default</span>:
        <span class="keyword">if</span> (!audio_is_linear_pcm(format)) {
                lStatus = BAD_VALUE;
                <span class="keyword">goto</span> Exit;
        }
        <span class="comment">// 如果采样率要src到很低的阈值，则ERROR提示。</span>
        <span class="keyword">if</span> (sampleRate &gt; mSampleRate * AUDIO_RESAMPLER_DOWN_RATIO_MAX) {
            lStatus = BAD_VALUE;
            <span class="keyword">goto</span> Exit;
        }
        <span class="keyword">break</span>;

    }
    <span class="comment">// 只是单纯的判断了下mOutput这个成员是否为空</span>
    lStatus = initCheck();
    <span class="keyword">if</span> (lStatus != NO_ERROR) {
        <span class="keyword">goto</span> Exit;
    }

    { <span class="comment">// scope for mLock</span>
        Mutex::Autolock _l(mLock);

        <span class="comment">// 所有的tracks使用相同的audio session必须共享相同的路由策略，否则当AudioPolicyManager在</span>
        <span class="comment">// 将tracks从一个output移到另外一个output的时候会产生冲突。</span>
        <span class="keyword">uint32_t</span> strategy = AudioSystem::getStrategyForStream(streamType);
        <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; mTracks.size(); ++i) {
            sp&lt;Track&gt; t = mTracks[i];
            <span class="keyword">if</span> (t != <span class="number">0</span> &amp;&amp; t-&gt;isExternalTrack()) {
                <span class="keyword">uint32_t</span> actual = AudioSystem::getStrategyForStream(t-&gt;streamType());
                <span class="keyword">if</span> (sessionId == t-&gt;sessionId() &amp;&amp; strategy != actual) {
                    lStatus = BAD_VALUE;
                    <span class="keyword">goto</span> Exit;
                }
            }
        }

        <span class="keyword">if</span> (!isTimed) {
            <span class="comment">// 创建track实例</span>
            track = <span class="keyword">new</span> Track(<span class="keyword">this</span>, client, streamType, sampleRate, format,
                              channelMask, frameCount, <span class="literal">NULL</span>, sharedBuffer,
                              sessionId, uid, *flags, TrackBase::TYPE_DEFAULT);
        } <span class="keyword">else</span> {
            <span class="comment">// 创建timetrack实例</span>
            track = TimedTrack::create(<span class="keyword">this</span>, client, streamType, sampleRate, format,
                    channelMask, frameCount, sharedBuffer, sessionId, uid);
        }

        <span class="comment">// Track通过new的方式，所以它肯定是non-NULL，所以需要进一步initCheck。</span>
        <span class="comment">// 而TimedTrack是通过工厂方法进行创建的，所以它可能返回null。</span>
        lStatus = track != <span class="number">0</span> ? track-&gt;initCheck() : (<span class="keyword">status_t</span>) NO_MEMORY;
        <span class="keyword">if</span> (lStatus != NO_ERROR) {
            <span class="comment">// track must be cleared from the caller as the caller has the AF lock</span>
            <span class="keyword">goto</span> Exit;
        }
        <span class="comment">// 将该track添加到thread的mTracks中。</span>
        mTracks.add(track);
        <span class="comment">// 获取这个sessionid的效果链</span>
        sp&lt;EffectChain&gt; chain = getEffectChain_l(sessionId);
        <span class="keyword">if</span> (chain != <span class="number">0</span>) {
            <span class="comment">// 不为0的话，则设置track的输出output为效果链的InBuffer。</span>
            track-&gt;setMainBuffer(chain-&gt;inBuffer());
            <span class="comment">// 设置效果链的策略为当前这个track的streamtype所获取到的策略。</span>
            chain-&gt;setStrategy(AudioSystem::getStrategyForStream(track-&gt;streamType()));
            <span class="comment">// 效果链中track引用计数加1.</span>
            chain-&gt;incTrackCnt();
        }
        <span class="comment">// flag含有fast标志，并且存在Callback。</span>
        <span class="keyword">if</span> ((*flags &amp; IAudioFlinger::TRACK_FAST) &amp;&amp; (tid != -<span class="number">1</span>)) {
            <span class="keyword">pid_t</span> callingPid = IPCThreadState::self()-&gt;getCallingPid();
            <span class="comment">// 用户进程没有CAP_SYS_NICE，但是我们又想该进程能够获取得高的调度权限(FIFO或者RR)，</span>
            <span class="comment">// 所以只能让系统进程管理（scheduling_policy）代我们来帮忙获取。</span>
            sendPrioConfigEvent_l(callingPid, tid, kPriorityAudioApp);
        }
    }

    lStatus = NO_ERROR;

Exit:
    *status = lStatus;
    <span class="keyword">return</span> track;
}
</code></pre><p>上面函数主要做了几件事：</p>
<ol>
<li>确认fast是否符合server端的要求</li>
<li>重新计算framecount</li>
<li>output的类型判断是否符合要求</li>
<li>创建track的实例</li>
<li>效果方面的设置</li>
<li>如果是fast的话，则申请调度权限</li>
</ol>
<p>我们重点是来看Track的创建了。</p>
<p>这个我们要分两部分来看，先看Track的基类TrackBase的构造函数：</p>
<pre><code>AudioFlinger::ThreadBase::TrackBase::TrackBase(
            ThreadBase *thread,
            <span class="keyword">const</span> sp&lt;Client&gt;&amp; client,<span class="comment">// 这个是AudioFlinger那边给构造的client</span>
            uint32_t sampleRate,
            audio_format_t format,
            audio_channel_mask_t channelMask,
            size_t frameCount,
            void *buffer,
            <span class="keyword">int</span> sessionId,
            <span class="keyword">int</span> clientUid,
            IAudioFlinger::track_flags_t flags,
            <span class="keyword">bool</span> isOut,
            alloc_type alloc,
            track_type type)
    :   RefBase(),
        mThread(thread),
        mClient(client),
        mCblk(<span class="keyword">NULL</span>),
        <span class="comment">// mBuffer</span>
        mState(IDLE),<span class="comment">//Track的初始状态为IDLE</span>
        mSampleRate(sampleRate),
        mFormat(format),
        mChannelMask(channelMask),
        mChannelCount(isOut ?
                audio_channel_count_from_out_mask(channelMask) :
                audio_channel_count_from_in_mask(channelMask)),
        <span class="comment">// mFrameSize,如果是线性pcm的话，则用通道数*采样精度。</span>
        mFrameSize(audio_is_linear_pcm(format) ?
                mChannelCount * audio_bytes_per_sample(format) : sizeof(int8_t)),
        mFrameCount(frameCount),
        mSessionId(sessionId),
        mFlags(flags),
        mIsOut(isOut),
        mServerProxy(<span class="keyword">NULL</span>),
        mId(android_atomic_inc(&amp;nextTrackId)),
        mTerminated(<span class="keyword">false</span>),
        mType(type),
        mThreadIoHandle(thread-&gt;id())
{
    <span class="comment">// if the caller is us, trust the specified uid</span>
    <span class="keyword">if</span> (IPCThreadState::self()-&gt;getCallingPid() != getpid_cached || clientUid == -<span class="number">1</span>) {
        <span class="keyword">int</span> newclientUid = IPCThreadState::self()-&gt;getCallingUid();
        <span class="keyword">if</span> (clientUid != -<span class="number">1</span> &amp;&amp; clientUid != newclientUid) {
            ALOGW(<span class="string">"uid %d tried to pass itself off as %d"</span>, newclientUid, clientUid);
        }
        clientUid = newclientUid;
    }
    <span class="comment">// clientUid contains the uid of the app that is responsible for this track, so we can blame</span>
    <span class="comment">// battery usage on it.</span>
    <span class="comment">// clientUid包含app的uid，是这个track的owner，所以对于耗电量我们可以来找它。</span>
    mUid = clientUid;

    size_t size = sizeof(audio_track_cblk_t);
    <span class="comment">// 如果buffer是为空，则roundup(frameCount)，否则就自带的</span>
    <span class="comment">// roundup(frameCount)就是的多一位2进制位。thread创建track的时候，传递进来的buffer为NULL</span>
    size_t bufferSize = (buffer == <span class="keyword">NULL</span> ? roundup(frameCount) : frameCount) * mFrameSize;
    <span class="keyword">if</span> (buffer == <span class="keyword">NULL</span> &amp;&amp; alloc == ALLOC_CBLK) {
        size += bufferSize;
    }

    <span class="keyword">if</span> (client != <span class="number">0</span>) {
        <span class="comment">// 这边采用到client进行空间的分配，后面针对这点在分析下</span>
        mCblkMemory = client-&gt;heap()-&gt;allocate(size);
        <span class="keyword">if</span> (mCblkMemory == <span class="number">0</span> ||
                <span class="comment">// 注意这边是有mCblk的赋值操作。</span>
                (mCblk = static_cast&lt;audio_track_cblk_t *&gt;(mCblkMemory-&gt;pointer())) == <span class="keyword">NULL</span>) {
            client-&gt;heap()-&gt;dump(<span class="string">"AudioTrack"</span>);
            mCblkMemory.clear();
            <span class="keyword">return</span>;
        }
    } <span class="keyword">else</span> {
        <span class="comment">// 如果client为0的话，则走这个分支，这种分配空间方式，可以免去调用结构体的构造函数。</span>
        mCblk = (audio_track_cblk_t *) <span class="keyword">new</span> uint8_t[size];
        <span class="comment">// assume mCblk != NULL</span>
    }

    <span class="comment">// construct the shared structure in-place.</span>
    <span class="keyword">if</span> (mCblk != <span class="keyword">NULL</span>) {
        <span class="comment">// 在指定的空间，调用audio_track_cblk_t的构造函数。</span>
        <span class="keyword">new</span>(mCblk) audio_track_cblk_t();
        <span class="keyword">switch</span> (alloc) {
        <span class="keyword">case</span> ALLOC_READONLY: {
            <span class="keyword">const</span> sp&lt;MemoryDealer&gt; roHeap(thread-&gt;readOnlyHeap());
            <span class="keyword">if</span> (roHeap == <span class="number">0</span> ||
                    (mBufferMemory = roHeap-&gt;allocate(bufferSize)) == <span class="number">0</span> ||
                    (mBuffer = mBufferMemory-&gt;pointer()) == <span class="keyword">NULL</span>) {
                ALOGE(<span class="string">"not enough memory for read-only buffer size=%zu"</span>, bufferSize);
                <span class="keyword">if</span> (roHeap != <span class="number">0</span>) {
                    roHeap-&gt;dump(<span class="string">"buffer"</span>);
                }
                mCblkMemory.clear();
                mBufferMemory.clear();
                <span class="keyword">return</span>;
            }
            memset(mBuffer, <span class="number">0</span>, bufferSize);
            } <span class="keyword">break</span>;
        <span class="keyword">case</span> ALLOC_PIPE:
            mBufferMemory = thread-&gt;pipeMemory();
            <span class="comment">// mBuffer is the virtual address as seen from current process (mediaserver),</span>
            <span class="comment">// and should normally be coming from mBufferMemory-&gt;pointer().</span>
            <span class="comment">// However in this case the TrackBase does not reference the buffer directly.</span>
            <span class="comment">// It should references the buffer via the pipe.</span>
            <span class="comment">// Therefore, to detect incorrect usage of the buffer, we set mBuffer to NULL.</span>
            mBuffer = <span class="keyword">NULL</span>;
            <span class="keyword">break</span>;
        <span class="keyword">case</span> ALLOC_CBLK:
            <span class="comment">// clear all buffers</span>
            <span class="keyword">if</span> (buffer == <span class="keyword">NULL</span>) {
                mBuffer = (<span class="keyword">char</span>*)mCblk + sizeof(audio_track_cblk_t);
                memset(mBuffer, <span class="number">0</span>, bufferSize);
            } <span class="keyword">else</span> {
                mBuffer = buffer;
<span class="comment">#if 0</span>
                mCblk-&gt;mFlags = CBLK_FORCEREADY;    <span class="comment">// FIXME hack, need to fix the track ready logic</span>
<span class="comment">#endif</span>
            }
            <span class="keyword">break</span>;
        <span class="keyword">case</span> ALLOC_LOCAL:
            mBuffer = calloc(<span class="number">1</span>, bufferSize);
            <span class="keyword">break</span>;
        <span class="keyword">case</span> ALLOC_NONE:
            mBuffer = buffer;
            <span class="keyword">break</span>;
        }

<span class="comment">#ifdef TEE_SINK</span>
        <span class="keyword">if</span> (mTeeSinkTrackEnabled) {
            NBAIO_Format pipeFormat = Format_from_SR_C(mSampleRate, mChannelCount, mFormat);
            <span class="keyword">if</span> (Format_isValid(pipeFormat)) {
                Pipe *pipe = <span class="keyword">new</span> Pipe(mTeeSinkTrackFrames, pipeFormat);
                size_t numCounterOffers = <span class="number">0</span>;
                <span class="keyword">const</span> NBAIO_Format offers[<span class="number">1</span>] = {pipeFormat};
                ssize_t index = pipe-&gt;negotiate(offers, <span class="number">1</span>, <span class="keyword">NULL</span>, numCounterOffers);
                ALOG_ASSERT(index == <span class="number">0</span>);
                PipeReader *pipeReader = <span class="keyword">new</span> PipeReader(*pipe);
                numCounterOffers = <span class="number">0</span>;
                index = pipeReader-&gt;negotiate(offers, <span class="number">1</span>, <span class="keyword">NULL</span>, numCounterOffers);
                ALOG_ASSERT(index == <span class="number">0</span>);
                mTeeSink = pipe;
                mTeeSource = pipeReader;
            }
        }
<span class="comment">#endif</span>

    }
}
</code></pre><p>这个函数主要是分配了buffer，并且初始化的cblk这个重要的管理结构体。需要注意的是，buffer的大小，并不是framecount*framesize，如果传进来的buffer是null的话，是有进行roundup的操作的，否则是原值（比如说sharebuffer的情况）。</p>
<p>接下来要看track的构造函数了：</p>
<pre><code>AudioFlinger::PlaybackThread::Track::Track(
            PlaybackThread *thread,
            <span class="keyword">const</span> sp&lt;Client&gt;&amp; client,
            <span class="keyword">audio_stream_type_t</span> streamType,
            <span class="keyword">uint32_t</span> sampleRate,
            <span class="keyword">audio_format_t</span> format,
            <span class="keyword">audio_channel_mask_t</span> channelMask,
            <span class="keyword">size_t</span> frameCount,
            <span class="keyword">void</span> *buffer,
            <span class="keyword">const</span> sp&lt;IMemory&gt;&amp; sharedBuffer,
            <span class="keyword">int</span> sessionId,
            <span class="keyword">int</span> uid,
            IAudioFlinger::<span class="keyword">track_flags_t</span> flags,
            track_type type)
    :   TrackBase(thread, client, sampleRate, format, channelMask, frameCount,
                  (sharedBuffer != <span class="number">0</span>) ? sharedBuffer-&gt;pointer() : buffer,
                  sessionId, uid, flags, <span class="literal">true</span> <span class="comment">/*isOut*/</span>,
                  <span class="comment">// 分配空间的方式，如果类型是patch，则选第一种方案，否则选择第二种方案</span>
                  <span class="comment">// ALLOC_CBLK，第一种方案还看buffer是否为NULL,为空的话就选择ALLOC_LOCAL，</span>
                  <span class="comment">// 否则为ALLOC_NONE</span>
                  (type == TYPE_PATCH) ? ( buffer == <span class="literal">NULL</span> ? ALLOC_LOCAL : ALLOC_NONE) : ALLOC_CBLK,
                  type),
    mFillingUpStatus(FS_INVALID),
    <span class="comment">// mRetryCount initialized later when needed</span>
    mSharedBuffer(sharedBuffer),
    mStreamType(streamType),
    mName(-<span class="number">1</span>),  <span class="comment">// see note below</span>
    mMainBuffer(thread-&gt;mixBuffer()),<span class="comment">// 如果有效果链的话，会被替换，目前还是指向线程的mixBuffer</span>
    mAuxBuffer(<span class="literal">NULL</span>),
    mAuxEffectId(<span class="number">0</span>), mHasVolumeController(<span class="literal">false</span>),
    mPresentationCompleteFrames(<span class="number">0</span>),
    mFastIndex(-<span class="number">1</span>),
    mCachedVolume(<span class="number">1.0</span>),
    mIsInvalid(<span class="literal">false</span>),
    mAudioTrackServerProxy(<span class="literal">NULL</span>),
    mResumeToStopping(<span class="literal">false</span>),
    mFlushHwPending(<span class="literal">false</span>)
{
    <span class="comment">// client == 0 意味着必须 sharedBuffer == 0</span>
    <span class="comment">// 但是目前位置client是不为0的，所以sharebuffer就随意了。</span>
    ALOG_ASSERT(!(client == <span class="number">0</span> &amp;&amp; sharedBuffer != <span class="number">0</span>));

    ALOGV_IF(sharedBuffer != <span class="number">0</span>, <span class="string">"sharedBuffer: %p, size: %d"</span>, sharedBuffer-&gt;pointer(),
            sharedBuffer-&gt;size());

    <span class="keyword">if</span> (mCblk == <span class="literal">NULL</span>) {
        <span class="keyword">return</span>;
    }

    <span class="keyword">if</span> (sharedBuffer == <span class="number">0</span>) {
        <span class="comment">// 创建AudioTrack server端的代理，流模式的。</span>
        mAudioTrackServerProxy = <span class="keyword">new</span> AudioTrackServerProxy(mCblk, mBuffer, frameCount,
                mFrameSize, !isExternalTrack(), sampleRate);
    } <span class="keyword">else</span> {
        <span class="comment">// 创建静态的AudioTrack server端的代理。</span>
        mAudioTrackServerProxy = <span class="keyword">new</span> StaticAudioTrackServerProxy(mCblk, mBuffer, frameCount,
                mFrameSize);
    }
    mServerProxy = mAudioTrackServerProxy;

    mName = thread-&gt;getTrackName_l(channelMask, format, sessionId);
    <span class="keyword">if</span> (mName &lt; <span class="number">0</span>) {
        ALOGE(<span class="string">"no more track names available"</span>);
        <span class="keyword">return</span>;
    }
    <span class="comment">// only allocate a fast track index if we were able to allocate a normal track name</span>
    <span class="keyword">if</span> (flags &amp; IAudioFlinger::TRACK_FAST) {
        <span class="comment">// 设置mFramesReadyIsCalledByMultipleThreads变量为true</span>
        mAudioTrackServerProxy-&gt;framesReadyIsCalledByMultipleThreads();
        ALOG_ASSERT(thread-&gt;mFastTrackAvailMask != <span class="number">0</span>);
        <span class="comment">// 获取从左往右第一个1的index</span>
        <span class="keyword">int</span> i = __builtin_ctz(thread-&gt;mFastTrackAvailMask);
        ALOG_ASSERT(<span class="number">0</span> &lt; i &amp;&amp; i &lt; (<span class="keyword">int</span>)FastMixerState::kMaxFastTracks);
        <span class="comment">// 既然fast track是稀缺资源，我们在fast track被激活前就给分配了，这样会把后面更重要的fast</span>
        <span class="comment">// track给拒之门外。</span>
        <span class="comment">// 动态的创建将会是更好的方案。 所以亟待解决。。。</span>
        mFastIndex = i;
        thread-&gt;mFastTrackAvailMask &amp;= ~(<span class="number">1</span> &lt;&lt; i);
    }
}
</code></pre><p>这边完成创建了server端的proxy了，刚才我们在看audiotrack那边的创建的时候也创建了自己的代理。</p>
<p>把所有的代码贴出来，主要是为了看到整个创建的细节，并不是为了单纯完成对流程的梳理，创建流程可以看下图：</p>
<p><img src="http://thinks.me/image/audiotrack_create.jpg" alt=""></p>
<p>这边我们再补充下AudioTrack那边创建的线程现在的状态：</p>
<pre><code>AudioTrack::AudioTrackThread::AudioTrackThread(AudioTrack&amp; receiver, bool bCanCallJava)
    : Thread(bCanCallJava), mReceiver(receiver), mPaused(<span class="keyword">true</span>), mPausedInt(<span class="keyword">false</span>), mPausedNs(0LL),
      mIgnoreNextPausedInt(<span class="keyword">false</span>)
{
}

bool AudioTrack::AudioTrackThread::threadLoop()
{
    {
        <span class="function">AutoMutex <span class="title">_l</span><span class="params">(mMyLock)</span></span>;
        <span class="comment">// 从构造函数中，我们看到了mPaused一开始被设置为true，所以线程刚跑起来是在这边等待的。</span>
        <span class="keyword">if</span> (mPaused) {
            mMyCond.wait(mMyLock);
            <span class="comment">// caller will check for exitPending()</span>
            <span class="keyword">return</span> <span class="keyword">true</span>;
        }
        <span class="keyword">if</span> (mIgnoreNextPausedInt) {
            mIgnoreNextPausedInt = <span class="keyword">false</span>;
            mPausedInt = <span class="keyword">false</span>;
        }
        <span class="keyword">if</span> (mPausedInt) {
            <span class="keyword">if</span> (mPausedNs &gt; <span class="number">0</span>) {
                (<span class="keyword">void</span>) mMyCond.waitRelative(mMyLock, mPausedNs);
            } <span class="keyword">else</span> {
                mMyCond.wait(mMyLock);
            }
            mPausedInt = <span class="keyword">false</span>;
            <span class="keyword">return</span> <span class="keyword">true</span>;
        }
    }
    <span class="keyword">if</span> (exitPending()) {
        <span class="keyword">return</span> <span class="keyword">false</span>;
    }
    nsecs_t ns = mReceiver.processAudioBuffer();
    <span class="keyword">switch</span> (ns) {
    <span class="keyword">case</span> <span class="number">0</span>:
        <span class="keyword">return</span> <span class="keyword">true</span>;
    <span class="keyword">case</span> NS_INACTIVE:
        pauseInternal();
        <span class="keyword">return</span> <span class="keyword">true</span>;
    <span class="keyword">case</span> NS_NEVER:
        <span class="keyword">return</span> <span class="keyword">false</span>;
    <span class="keyword">case</span> NS_WHENEVER:
        // Event driven: call wake() when callback notifications conditions change.
        ns = INT64_MAX;
        <span class="comment">// fall through</span>
    <span class="keyword">default</span>:
        LOG_ALWAYS_FATAL_IF(ns &lt; 0, <span class="string">"processAudioBuffer() returned %"</span> PRId64, ns);
        pauseInternal(ns);
        <span class="keyword">return</span> <span class="keyword">true</span>;
    }
}
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/12/19/audioflinger_buffer/" itemprop="url">
                  AudioFlinger Thread中的几个buffer
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2015-12-19T23:46:31+08:00" content="2015-12-19">
              2015-12-19
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/android开发/" itemprop="url" rel="index">
                    <span itemprop="name">android开发</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2015/12/19/audioflinger_buffer/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2015/12/19/audioflinger_buffer/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h3 id="简述">简述</h3><p>AudioFlinger是实现上层跟Hal层进行交互的重要的一层，它主要就是通过Thread进行沟通，不管是数据流还是控制流都是需要经由AudioFlinger Thread往下分发的。这两天有空梳理了一下Thread中几个重要的buffer，在这边做个总结，东西很浅，留作备忘。<br>
          <div class="post-more-link text-center">
            <a class="btn" href="/2015/12/19/audioflinger_buffer/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/12/13/android_tts/" itemprop="url">
                  Android TTS学习
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2015-12-13T21:59:29+08:00" content="2015-12-13">
              2015-12-13
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/android开发/" itemprop="url" rel="index">
                    <span itemprop="name">android开发</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2015/12/13/android_tts/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2015/12/13/android_tts/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h3 id="简述">简述</h3><p>TTS是Text To Speech的简称，就是将字符串转换成语音。Talkback是用来给帮助盲人朋友使用手机的apk，是android辅助功能的插件，安装完之后可以到辅助功能里面使能它，之后只要你触摸到android系统中的任何控件，都会将控件中的信息转变成语音的形式播放出来。<br>
          <div class="post-more-link text-center">
            <a class="btn" href="/2015/12/13/android_tts/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/11/22/dagger2_second/" itemprop="url">
                  Dagger 2 SubComponent
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2015-11-22T14:26:02+08:00" content="2015-11-22">
              2015-11-22
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/android开发/" itemprop="url" rel="index">
                    <span itemprop="name">android开发</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2015/11/22/dagger2_second/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2015/11/22/dagger2_second/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>学习源码：<a href="https://github.com/mvarnagiris/Financius">https://github.com/mvarnagiris/Financius</a></p>
<p>本来该文章打算稍微介绍下Dagger2的SubComponent的，但是发现单单介绍这个标签好像并没有什么卵用，因为它的使用方法跟Component基本上没有太大区别。</p>
<h3 id="SubComponent的使用">SubComponent的使用</h3><p>SubComponent的语法规则可以参考前一篇博客里面的Component的使用。</p>
<p>那如何将Component和SubComponent关联起来呢？</p>
<blockquote>
<p>只需要在Component中声明一个函数返回值为该SubComponent即可：</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ActivityComponent <span class="title">plus</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>
<p>那SubComponent在apt生成的代码中的表现形式又是如何的呢？</p>
<blockquote>
<p>该SubComponent的实现类将直接成为Component的private final内部类。而如果是独立的Component，那它将拥有自己的一个public的实现类。由于是private final类，所以获取该SubComponent只能通过在Component中声明的函数进行获取。</p>
</blockquote>
          <div class="post-more-link text-center">
            <a class="btn" href="/2015/11/22/dagger2_second/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/11/13/dagger2_first/" itemprop="url">
                  Dagger 2 Component/Module/Inject的理解
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2015-11-13T21:55:09+08:00" content="2015-11-13">
              2015-11-13
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/android开发/" itemprop="url" rel="index">
                    <span itemprop="name">android开发</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2015/11/13/dagger2_first/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2015/11/13/dagger2_first/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h3 id="简述">简述</h3><p>  我只想简简单单的描述下我对该框架使用上的理解。。<br>  而这些的理解来自于别人的文档、看别人代码、实践。<br>  不过还是得对这个框架有个初步的认识：这个框架作用，给某些类或方法提供依赖。是DI思想的一种呈现。主要手段是帮你构建工厂类。</p>
<ul>
<li>Component：首先，它是一个interface，其次，它的作用是将Module和Host进行关联，关联生效的时机是在host中调用了inject函数（这个函数是你在components中声明的方法）。由于上面的特性，所以Component是有作用域的，利用这个作用域就可以引入singleon和scope provider了。</li>
<li>Module或Inject:Module和Inject都是class，Module可以给host提供多个依赖的对象，而Inject本身就是host依赖的对象。（这里面提到的Inject是在类的构造函数前面标注@Inject，表示自己可以提供依赖）</li>
<li><p>被注入依赖的对象：这里我们称之为host（宿主）</p>
<p>如果你对butterknife熟悉的话，那你可以把这个理解称为butterknife在类上面的扩展，更加的自由，但是前提是你也必须写更多的代码。</p>
          <div class="post-more-link text-center">
            <a class="btn" href="/2015/11/13/dagger2_first/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
        
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="LexiMee" />
          <p class="site-author-name" itemprop="name">LexiMee</p>
          <p class="site-description motion-element" itemprop="description">leave me alone</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">8</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        <div class="links-of-blogroll motion-element">
          
        </div>

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LexiMee</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>



      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  


  




<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=0.5.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=0.5.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=0.5.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"thinks"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
  





  
  
  

  


</body>
</html>
